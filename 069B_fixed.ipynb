{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "authorship_tag": "ABX9TyP2bzzPvc3L8IdMCIYZIdgq"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cognitive tests"
   ],
   "metadata": {
    "id": "cjJfiAsti5aR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qb8TqXhwi4l6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1769251272936,
     "user_tz": -480,
     "elapsed": 546645,
     "user": {
      "displayName": "Ngo Cheung",
      "userId": "02091267041339546959"
     }
    },
    "outputId": "93736ef1-91b1-4dac-ff21-c01646302481"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "█                                                                              █\n",
      "█             COMPUTATIONAL MODEL: OCD SYNAPTIC PRUNING HYPOTHESIS             █\n",
      "█               WITH COGNITIVE TESTING THROUGHOUT ILLNESS COURSE               █\n",
      "█                    AND ISO-DOSE FAIR COMPARISON PIPELINE                     █\n",
      "█                                                                              █\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "\n",
      "  PyTorch Version: 2.9.0+cu126\n",
      "  Device: cuda\n",
      "  CUDA Available: True\n",
      "\n",
      "  Running Multi-Mechanism Comparison (with cognitive tracking)...\n",
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "                   MULTI-MECHANISM ANTIDEPRESSANT COMPARISON                    \n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "                   WITH COGNITIVE TESTING THROUGHOUT ILLNESS                    \n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "\n",
      "  Comparing treatment mechanisms in OCD model (Seed: 42)\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 1: Creating Shared Pruned Baseline\n",
      "------------------------------------------------------------\n",
      "  Training healthy baseline model...\n",
      "  Applied developmental over-pruning: 95%\n",
      "  Achieved sparsity: 95.0%\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 2: Untreated Baseline Evaluation\n",
      "------------------------------------------------------------\n",
      "  UNTREATED OCD STATE:\n",
      "    Sparsity:              95.0%\n",
      "    Accuracy:              0.2991\n",
      "    Perseverative Errors:  0.8793\n",
      "    Flexibility Index:     0.9730\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 3: KETAMINE Treatment\n",
      "------------------------------------------------------------\n",
      "      [KETAMINE] regrow_fraction=0.60, consolidation=10 epochs\n",
      "\n",
      "    DOSE METRICS:\n",
      "      L1 Weight Change:    0.011646\n",
      "      L2 Weight Change:    0.000071\n",
      "      Synaptic Turnover:   0.5876\n",
      "      Sparsity Change:     0.5680\n",
      "\n",
      "    ACUTE EFFECTS:\n",
      "      Sparsity:            38.2%\n",
      "      Accuracy:            0.7479 (Δ = +0.4487)\n",
      "      Perseveration:       0.2361 (Δ = -0.6431)\n",
      "      Flexibility:         0.9821 (Δ = +0.0091)\n",
      "      Efficiency:          55.22 (persev reduction / dose)\n",
      "\n",
      "    RELAPSE SIMULATION (40% secondary pruning):\n",
      "      Sparsity:            62.9%\n",
      "      Perseveration:       0.2561 (Δ = +0.0199)\n",
      "      Flexibility:         0.9802 (Δ = -0.0019)\n",
      "\n",
      "    COGNITIVE TRAJECTORY SUMMARY:\n",
      "      [pre_treatment] before_regrowth: Acc=0.3103, Persev=0.8478, Rot=0.2633\n",
      "      [during_treatment] post_regrowth_pre_consolidation: Acc=0.3103, Persev=0.8478, Rot=0.2633\n",
      "      [post_treatment] after_consolidation: Acc=0.7507, Persev=0.2769, Rot=0.4837\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 3: SSRI Treatment\n",
      "------------------------------------------------------------\n",
      "      [SSRI] epochs=120, lr=1e-05, initial_stress=0.40\n",
      "\n",
      "    DOSE METRICS:\n",
      "      L1 Weight Change:    0.000926\n",
      "      L2 Weight Change:    0.000017\n",
      "      Synaptic Turnover:   0.0034\n",
      "      Sparsity Change:     0.0000\n",
      "\n",
      "    ACUTE EFFECTS:\n",
      "      Sparsity:            95.0%\n",
      "      Accuracy:            0.4552 (Δ = +0.1561)\n",
      "      Perseveration:       0.7500 (Δ = -0.1293)\n",
      "      Flexibility:         0.9775 (Δ = +0.0045)\n",
      "      Efficiency:          139.62 (persev reduction / dose)\n",
      "\n",
      "    RELAPSE SIMULATION (40% secondary pruning):\n",
      "      Sparsity:            97.0%\n",
      "      Perseveration:       0.8065 (Δ = +0.0565)\n",
      "      Flexibility:         0.9774 (Δ = -0.0001)\n",
      "\n",
      "    COGNITIVE TRAJECTORY SUMMARY:\n",
      "      [pre_treatment] before_training: Acc=0.3103, Persev=0.8478, Rot=0.2633\n",
      "      [mid_treatment] epoch_30/120: Acc=0.3435, Persev=0.8096, Rot=0.2626\n",
      "      [mid_treatment] epoch_60/120: Acc=0.3820, Persev=0.7930, Rot=0.2615\n",
      "      [mid_treatment] epoch_90/120: Acc=0.4175, Persev=0.7587, Rot=0.2628\n",
      "      [post_treatment] after_full_course: Acc=0.4605, Persev=0.7311, Rot=0.2657\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 3: NEUROSTEROID Treatment\n",
      "------------------------------------------------------------\n",
      "      [NEUROSTEROID] strength=0.65, use_tanh=True, consolidation=8 epochs\n",
      "\n",
      "    DOSE METRICS:\n",
      "      L1 Weight Change:    0.001966\n",
      "      L2 Weight Change:    0.000040\n",
      "      Synaptic Turnover:   0.0344\n",
      "      Sparsity Change:     0.0000\n",
      "\n",
      "    ACUTE EFFECTS:\n",
      "      Sparsity:            95.0%\n",
      "      Accuracy:            0.5627 (Δ = +0.2636)\n",
      "      Perseveration:       0.6533 (Δ = -0.2259)\n",
      "      Flexibility:         0.9777 (Δ = +0.0046)\n",
      "      Efficiency:          114.90 (persev reduction / dose)\n",
      "\n",
      "    OFF-MEDICATION TEST:\n",
      "      Perseveration:       0.6654\n",
      "      Reversal:            +0.0121 perseveration increase\n",
      "\n",
      "    RELAPSE SIMULATION (40% secondary pruning):\n",
      "      Sparsity:            97.0%\n",
      "      Perseveration:       0.8161 (Δ = +0.1627)\n",
      "      Flexibility:         0.9771 (Δ = -0.0005)\n",
      "\n",
      "    COGNITIVE TRAJECTORY SUMMARY:\n",
      "      [pre_treatment] before_medication: Acc=0.3103, Persev=0.8478, Rot=0.2633\n",
      "      [during_treatment] immediate_medication_effect: Acc=0.3185, Persev=0.8324, Rot=0.2637\n",
      "      [post_treatment] after_consolidation_on_med: Acc=0.5502, Persev=0.6597, Rot=0.3098\n",
      "      [off_medication] medication_discontinued: Acc=0.5456, Persev=0.6356, Rot=0.2956\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "                       COMPREHENSIVE TREATMENT COMPARISON                       \n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "  DOSE COMPARISON:\n",
      "  Treatment            L1 Dose      L2 Dose     Turnover    ΔSparsity\n",
      "  -----------------------------------------------------------------\n",
      "  Ketamine            0.011646     0.000071       0.5876       0.5680\n",
      "  Ssri                0.000926     0.000017       0.0034       0.0000\n",
      "  Neurosteroid        0.001966     0.000040       0.0344       0.0000\n",
      "\n",
      "  ACUTE EFFECTS:\n",
      "  Treatment         Sparsity   Accuracy     Persev       Flex   Efficiency\n",
      "  ----------------------------------------------------------------------\n",
      "  Untreated            95.0%     0.2991     0.8793     0.9730          N/A\n",
      "  Ketamine             38.2%     0.7479     0.2361     0.9821        55.22\n",
      "  Ssri                 95.0%     0.4552     0.7500     0.9775       139.62\n",
      "  Neurosteroid         95.0%     0.5627     0.6533     0.9777       114.90\n",
      "\n",
      "  RELAPSE VULNERABILITY:\n",
      "  Treatment            ΔPersev ΔFlexibility Interpretation           \n",
      "  ----------------------------------------------------------------------\n",
      "  Ketamine             +0.0199      -0.0019 Relapse resistant        \n",
      "  Ssri                 +0.0565      -0.0001 High relapse risk        \n",
      "  Neurosteroid         +0.1627      -0.0005 High relapse risk        \n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "                     COGNITIVE COMPARISON ACROSS TREATMENTS                     \n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "------------------------------------------------------------\n",
      "  POST-TREATMENT COGNITIVE STATE\n",
      "------------------------------------------------------------\n",
      "\n",
      "  Standard Task Performance:\n",
      "  Condition                Accuracy       Persev  Flexibility\n",
      "  ----------------------------------------------------------\n",
      "  Healthy Baseline           0.7598       0.2808       0.9604\n",
      "  OCD Onset                  0.3103       0.8478       0.9520\n",
      "  Ketamine (Post-Tx)         0.7507       0.2769       0.9653\n",
      "  Ssri (Post-Tx)             0.4605       0.7311       0.9528\n",
      "  Neurosteroid (Post-Tx)       0.5502       0.6597       0.9831\n",
      "\n",
      "  Cognitive Probe Performance (Accuracy):\n",
      "  Condition              Rotation    Scaling  Fine Disc High Noise\n",
      "  --------------------------------------------------------------\n",
      "  Healthy Baseline         0.5339     0.7655     0.7269     0.7602\n",
      "  OCD Onset                0.2633     0.3153     0.3049     0.3101\n",
      "  Ketamine (Post-Tx)       0.4837     0.7601     0.7101     0.7494\n",
      "  Ssri (Post-Tx)           0.2657     0.4518     0.4600     0.4450\n",
      "  Neurosteroid (Post-Tx)     0.3098     0.5552     0.5198     0.5458\n",
      "\n",
      "  Sensory Integration (Blend Probes):\n",
      "  Condition               Blend 25%    Blend 50%    Blend 75%\n",
      "  ----------------------------------------------------------\n",
      "  Healthy Baseline           0.7160       0.6542       0.5904\n",
      "  OCD Onset                  0.2936       0.2932       0.2776\n",
      "  Ketamine (Post-Tx)         0.7146       0.6563       0.5958\n",
      "  Ssri (Post-Tx)             0.4424       0.4166       0.3890\n",
      "  Neurosteroid (Post-Tx)       0.5402       0.5134       0.4713\n",
      "\n",
      "------------------------------------------------------------\n",
      "  COGNITIVE IMPACT OF RELAPSE\n",
      "------------------------------------------------------------\n",
      "\n",
      "  Change in Cognitive Performance After Relapse:\n",
      "  Treatment           ΔStd Acc    ΔRotation   ΔFine Disc   ΔBlend 50%\n",
      "  -----------------------------------------------------------------\n",
      "  Ketamine             -0.0298      -0.1577      -0.0440      -0.0069\n",
      "  Ssri                 -0.0620      +0.0710      -0.0827      -0.0320\n",
      "  Neurosteroid         -0.1156      +0.0899      -0.1082      -0.0798\n",
      "\n",
      "  Running Iso-Dose Comparison Experiment (with cognitive tracking)...\n",
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "                      ISO-DOSE FAIR COMPARISON EXPERIMENT                       \n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "                WITH COGNITIVE TESTING THROUGHOUT ILLNESS COURSE                \n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "\n",
      "  Seed: 42\n",
      "  Device: cuda\n",
      "  Dose metric: L1 weight change norm (normalized per parameter)\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 1: Creating Shared Pruned Baseline\n",
      "------------------------------------------------------------\n",
      "  Evaluating pre-training (random initialization) cognitive state...\n",
      "  Training healthy baseline model...\n",
      "  Evaluating healthy trained baseline cognitive state...\n",
      "  Applied developmental over-pruning: 95%\n",
      "  Achieved sparsity: 95.0%\n",
      "  Evaluating post-pruning (OCD onset) cognitive state...\n",
      "\n",
      "  UNTREATED OCD BASELINE:\n",
      "    Perseverative Errors: 0.8793\n",
      "    Flexibility Index:    0.9730\n",
      "    Accuracy:             0.2991\n",
      "\n",
      "------------------------------------------------------------\n",
      "  COGNITIVE STATE: HEALTHY vs OCD ONSET\n",
      "------------------------------------------------------------\n",
      "\n",
      "    ================================================================================\n",
      "    COGNITIVE COMPARISON: HEALTHY_BASELINE\n",
      "    ================================================================================\n",
      "\n",
      "    Probe                          Healthy         OCD_Onset\n",
      "    --------------------------------------------------------------------------------\n",
      "    Standard Acc                    0.7598               N/A\n",
      "    Standard Persev                 0.2808               N/A\n",
      "    Rotation Acc                    0.5339               N/A\n",
      "    Rotation Persev                 0.2474               N/A\n",
      "    Scaling Acc                     0.7655               N/A\n",
      "    Fine Disc Acc                   0.7269               N/A\n",
      "    High Noise Acc                  0.7602               N/A\n",
      "    High Stress Acc                 0.7376               N/A\n",
      "    Blend 25%                       0.7160               N/A\n",
      "    Blend 50%                       0.6542               N/A\n",
      "    Blend 75%                       0.5904               N/A\n",
      "\n",
      "    ================================================================================\n",
      "    COGNITIVE COMPARISON: OCD_ONSET\n",
      "    ================================================================================\n",
      "\n",
      "    Probe                          Healthy         OCD_Onset\n",
      "    --------------------------------------------------------------------------------\n",
      "    Standard Acc                       N/A            0.3103\n",
      "    Standard Persev                    N/A            0.8478\n",
      "    Rotation Acc                       N/A            0.2633\n",
      "    Rotation Persev                    N/A            0.8493\n",
      "    Scaling Acc                        N/A            0.3153\n",
      "    Fine Disc Acc                      N/A            0.3049\n",
      "    High Noise Acc                     N/A            0.3101\n",
      "    High Stress Acc                    N/A            0.3201\n",
      "    Blend 25%                          N/A            0.2936\n",
      "    Blend 50%                          N/A            0.2932\n",
      "    Blend 75%                          N/A            0.2776\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 2: Parameter Sweeps (Measuring Dose-Response + Cognition)\n",
      "------------------------------------------------------------\n",
      "\n",
      "  [KETAMINE] Sweeping regrow_fraction...\n",
      "    Completed 8 configurations\n",
      "\n",
      "  [SSRI] Sweeping epochs...\n",
      "    Completed 8 configurations\n",
      "\n",
      "  [NEUROSTEROID] Sweeping strength...\n",
      "    Completed 8 configurations\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 3: Dose-Response Curves\n",
      "------------------------------------------------------------\n",
      "\n",
      "  KETAMINE DOSE-RESPONSE:\n",
      "   regrow_frac      L1 Dose     Turnover   Acute Prsv    Relapse Δ\n",
      "  ----------------------------------------------------------------\n",
      "          0.10     0.004513       0.1264       0.3383      +0.0335\n",
      "          0.20     0.006244       0.2169       0.2500      +0.0397\n",
      "          0.30     0.007688       0.3089       0.2421      +0.0141\n",
      "          0.40     0.009010       0.4014       0.2414      +0.0165\n",
      "          0.50     0.010301       0.4943       0.2374      +0.0148\n",
      "          0.60     0.011654       0.5878       0.2348      +0.0118\n",
      "          0.70     0.013056       0.6813       0.2351      +0.0115\n",
      "          0.80     0.014441       0.7751       0.2325      +0.0141\n",
      "\n",
      "  SSRI DOSE-RESPONSE:\n",
      "        epochs      L1 Dose     Turnover   Acute Prsv    Relapse Δ\n",
      "  ----------------------------------------------------------------\n",
      "            20     0.000156       0.0000       0.8632      -0.0817\n",
      "            40     0.000313       0.0000       0.8423      -0.1140\n",
      "            60     0.000470       0.0000       0.8196      -0.1667\n",
      "            80     0.000625       0.0000       0.7882      -0.0314\n",
      "           100     0.000777       0.0003       0.7683      +0.0461\n",
      "           120     0.000926       0.0034       0.7492      +0.0573\n",
      "           160     0.001175       0.0215       0.7088      +0.1026\n",
      "           200     0.001360       0.0297       0.6950      +0.1518\n",
      "\n",
      "  NEUROSTEROID DOSE-RESPONSE:\n",
      "      strength      L1 Dose     Turnover   Acute Prsv    Off-med Δ    Relapse Δ\n",
      "  ----------------------------------------------------------------------------\n",
      "          0.50     0.002223       0.0367       0.6669      +0.0203      +0.1494\n",
      "          0.55     0.002118       0.0359       0.6582      +0.0162      +0.1642\n",
      "          0.60     0.002034       0.0351       0.6538      +0.0104      +0.1646\n",
      "          0.65     0.001966       0.0345       0.6526      +0.0133      +0.1670\n",
      "          0.70     0.001923       0.0341       0.6574      +0.0123      +0.1499\n",
      "          0.75     0.001898       0.0341       0.6518      +0.0066      +0.1535\n",
      "          0.80     0.001898       0.0343       0.6512      +0.0020      +0.1562\n",
      "          0.85     0.001904       0.0346       0.6526      +0.0022      +0.1634\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 4: Iso-Dose Matched Comparisons\n",
      "------------------------------------------------------------\n",
      "\n",
      "  Observed dose range: 0.000156 - 0.014441\n",
      "  Target doses: [0.005, 0.01]\n",
      "\n",
      "  ISO-DOSE TARGET: 0.005000\n",
      "  ======================================================================\n",
      "\n",
      "  Treatment       Param            Actual Dose   Acute Prsv    Relapse Δ   Efficiency\n",
      "  --------------------------------------------------------------------------------\n",
      "  Ketamine        regrow_fraction=0.1     0.004513       0.3383      +0.0335       119.89\n",
      "  SSRI            epochs=200          0.001360       0.6950      +0.1518       135.47\n",
      "  Neurosteroid    strength=0.5        0.002223       0.6669      +0.1494        95.51\n",
      "\n",
      "  ISO-DOSE TARGET: 0.010000\n",
      "  ======================================================================\n",
      "\n",
      "  Treatment       Param            Actual Dose   Acute Prsv    Relapse Δ   Efficiency\n",
      "  --------------------------------------------------------------------------------\n",
      "  Ketamine        regrow_fraction=0.5     0.010301       0.2374      +0.0148        62.31\n",
      "  SSRI            epochs=200          0.001360       0.6950      +0.1518       135.47\n",
      "  Neurosteroid    strength=0.5        0.002223       0.6669      +0.1494        95.51\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 5: Treatment Efficiency Analysis\n",
      "------------------------------------------------------------\n",
      "\n",
      "  EFFICIENCY = (Perseveration Reduction) / (L1 Dose)\n",
      "  Higher efficiency = better outcome per unit of network change\n",
      "\n",
      "  KETAMINE EFFICIENCY:\n",
      "   regrow_frac         Dose   Prsv Reduc   Efficiency\n",
      "  ----------------------------------------------------\n",
      "          0.10     0.004513       0.5410       119.89\n",
      "          0.20     0.006244       0.6293       100.78\n",
      "          0.30     0.007688       0.6372        82.88\n",
      "          0.40     0.009010       0.6379        70.80\n",
      "          0.50     0.010301       0.6419        62.31\n",
      "          0.60     0.011654       0.6444        55.30\n",
      "          0.70     0.013056       0.6441        49.34\n",
      "          0.80     0.014441       0.6468        44.79\n",
      "\n",
      "  SSRI EFFICIENCY:\n",
      "        epochs         Dose   Prsv Reduc   Efficiency\n",
      "  ----------------------------------------------------\n",
      "            20     0.000156       0.0161       102.72\n",
      "            40     0.000313       0.0370       118.00\n",
      "            60     0.000470       0.0597       127.07\n",
      "            80     0.000625       0.0911       145.69\n",
      "           100     0.000777       0.1110       142.82\n",
      "           120     0.000926       0.1300       140.43\n",
      "           160     0.001175       0.1705       145.16\n",
      "           200     0.001360       0.1842       135.47\n",
      "\n",
      "  NEUROSTEROID EFFICIENCY:\n",
      "      strength         Dose   Prsv Reduc   Efficiency\n",
      "  ----------------------------------------------------\n",
      "          0.50     0.002223       0.2124        95.51\n",
      "          0.55     0.002118       0.2211       104.39\n",
      "          0.60     0.002034       0.2255       110.86\n",
      "          0.65     0.001966       0.2267       115.32\n",
      "          0.70     0.001923       0.2219       115.39\n",
      "          0.75     0.001898       0.2275       119.84\n",
      "          0.80     0.001898       0.2281       120.16\n",
      "          0.85     0.001904       0.2266       119.05\n",
      "\n",
      "------------------------------------------------------------\n",
      "  PHASE 6: Summary Statistics\n",
      "------------------------------------------------------------\n",
      "\n",
      "  TREATMENT SUMMARY:\n",
      "  Metric                           Ketamine            SSRI    Neurosteroid\n",
      "  ---------------------------------------------------------------------------\n",
      "  Dose Range (L1)           0.0045-0.0144   0.0002-0.0014   0.0019-0.0022\n",
      "  Best Acute Persev                  0.2325          0.6950          0.6512\n",
      "  Best Relapse Δ                    +0.0115         -0.1667         +0.1494\n",
      "  Max Efficiency                     119.89          145.69          120.16\n",
      "  Mean Efficiency                     73.26          132.17          112.56\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "              DETAILED COGNITIVE RESULTS THROUGHOUT ILLNESS COURSE              \n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "------------------------------------------------------------\n",
      "  COGNITIVE DECLINE: HEALTHY BASELINE → OCD ONSET\n",
      "------------------------------------------------------------\n",
      "\n",
      "    HEALTHY BASELINE:\n",
      "      Stage: healthy_baseline | Treatment: none | fully_trained_healthy\n",
      "      Network State: Sparsity=0.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.7598     0.2808     0.9604\n",
      "      Rotation (45°)           0.5339     0.2474     0.9954\n",
      "      Scaling (1.5x)           0.7655     0.2742     0.9950\n",
      "      Fine Discrimination      0.7269     0.2236     1.0271\n",
      "      High Noise               0.7602     0.2617     1.0683\n",
      "      High Stress              0.7376     0.2857     0.9856\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.7160\n",
      "        50% Conflict: 0.6542\n",
      "        75% Conflict: 0.5904\n",
      "\n",
      "    OCD ONSET (POST-PRUNING):\n",
      "      Stage: ocd_onset | Treatment: untreated | immediately_post_pruning\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3103     0.8478     0.9520\n",
      "      Rotation (45°)           0.2633     0.8493     0.9677\n",
      "      Scaling (1.5x)           0.3153     0.8843     1.0266\n",
      "      Fine Discrimination      0.3049     0.8798     1.0067\n",
      "      High Noise               0.3101     0.8632     0.9487\n",
      "      High Stress              0.3201     0.8113     0.9907\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.2936\n",
      "        50% Conflict: 0.2932\n",
      "        75% Conflict: 0.2776\n",
      "\n",
      "    COGNITIVE DECLINE (OCD Onset - Healthy):\n",
      "      Standard Accuracy:     -0.4495\n",
      "      Standard Persev:       +0.5669\n",
      "      Rotation Accuracy:     -0.2706\n",
      "      Fine Disc Accuracy:    -0.4220\n",
      "      Blend 50% Accuracy:    -0.3610\n",
      "\n",
      "------------------------------------------------------------\n",
      "  COGNITIVE TRAJECTORIES BY TREATMENT\n",
      "------------------------------------------------------------\n",
      "\n",
      "  KETAMINE (Best config: regrow_fraction=0.80)\n",
      "\n",
      "    ======================================================================\n",
      "    COGNITIVE TRAJECTORY: KETAMINE\n",
      "    ======================================================================\n",
      "\n",
      "    [1] PRE_TREATMENT - before_regrowth\n",
      "    ------------------------------------------------------------\n",
      "      Stage: pre_treatment | Treatment: ketamine | before_regrowth\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3103     0.8478     0.9520\n",
      "      Rotation (45°)           0.2633     0.8493     0.9677\n",
      "      Scaling (1.5x)           0.3153     0.8843     1.0266\n",
      "      Fine Discrimination      0.3049     0.8798     1.0067\n",
      "      High Noise               0.3101     0.8632     0.9487\n",
      "      High Stress              0.3204     0.8095     0.9112\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.2942\n",
      "        50% Conflict: 0.2908\n",
      "        75% Conflict: 0.2825\n",
      "\n",
      "    [2] DURING_TREATMENT - post_regrowth_pre_consolidation\n",
      "    ------------------------------------------------------------\n",
      "      Stage: during_treatment | Treatment: ketamine | post_regrowth_pre_consolidation\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3103     0.8478     0.9520\n",
      "      Rotation (45°)           0.2633     0.8493     0.9677\n",
      "      Scaling (1.5x)           0.3153     0.8843     1.0266\n",
      "      Fine Discrimination      0.3049     0.8798     1.0067\n",
      "      High Noise               0.3101     0.8632     0.9487\n",
      "      High Stress              0.3211     0.7994     0.9547\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.2932\n",
      "        50% Conflict: 0.2867\n",
      "        75% Conflict: 0.2863\n",
      "\n",
      "    [3] POST_TREATMENT - after_consolidation\n",
      "    ------------------------------------------------------------\n",
      "      Stage: post_treatment | Treatment: ketamine | after_consolidation\n",
      "      Network State: Sparsity=19.3%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.7513     0.2725     0.9622\n",
      "      Rotation (45°)           0.4854     0.2431     0.9983\n",
      "      Scaling (1.5x)           0.7606     0.2782     0.9912\n",
      "      Fine Discrimination      0.7106     0.2378     1.0073\n",
      "      High Noise               0.7508     0.2500     1.0651\n",
      "      High Stress              0.7351     0.2619     0.9657\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.7155\n",
      "        50% Conflict: 0.6566\n",
      "        75% Conflict: 0.5917\n",
      "\n",
      "  SSRI (Best config: epochs=200)\n",
      "\n",
      "    ======================================================================\n",
      "    COGNITIVE TRAJECTORY: SSRI\n",
      "    ======================================================================\n",
      "\n",
      "    [1] PRE_TREATMENT - before_training\n",
      "    ------------------------------------------------------------\n",
      "      Stage: pre_treatment | Treatment: ssri | before_training\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3103     0.8478     0.9520\n",
      "      Rotation (45°)           0.2633     0.8493     0.9677\n",
      "      Scaling (1.5x)           0.3153     0.8843     1.0266\n",
      "      Fine Discrimination      0.3049     0.8798     1.0067\n",
      "      High Noise               0.3101     0.8632     0.9487\n",
      "      High Stress              0.3194     0.8159     0.9171\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.2931\n",
      "        50% Conflict: 0.2881\n",
      "        75% Conflict: 0.2817\n",
      "\n",
      "    [2] MID_TREATMENT - epoch_50/200\n",
      "    ------------------------------------------------------------\n",
      "      Stage: mid_treatment | Treatment: ssri | epoch_50/200\n",
      "      Network State: Sparsity=95.0%, Stress=0.302, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3659     0.7709     0.9395\n",
      "      Rotation (45°)           0.2634     0.7407     0.9177\n",
      "      Scaling (1.5x)           0.3634     0.8288     1.0204\n",
      "      Fine Discrimination      0.3612     0.7849     1.0009\n",
      "      High Noise               0.3561     0.7930     0.9566\n",
      "      High Stress              0.3686     0.7839     0.9243\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.3482\n",
      "        50% Conflict: 0.3324\n",
      "        75% Conflict: 0.3213\n",
      "\n",
      "    [3] MID_TREATMENT - epoch_100/200\n",
      "    ------------------------------------------------------------\n",
      "      Stage: mid_treatment | Treatment: ssri | epoch_100/200\n",
      "      Network State: Sparsity=95.0%, Stress=0.201, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.4328     0.7422     0.9290\n",
      "      Rotation (45°)           0.2613     0.6484     0.9852\n",
      "      Scaling (1.5x)           0.4299     0.7761     1.0194\n",
      "      Fine Discrimination      0.4303     0.7271     0.9750\n",
      "      High Noise               0.4196     0.7540     0.9395\n",
      "      High Stress              0.4198     0.6842     0.9498\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.4083\n",
      "        50% Conflict: 0.3950\n",
      "        75% Conflict: 0.3655\n",
      "\n",
      "    [4] MID_TREATMENT - epoch_150/200\n",
      "    ------------------------------------------------------------\n",
      "      Stage: mid_treatment | Treatment: ssri | epoch_150/200\n",
      "      Network State: Sparsity=95.0%, Stress=0.101, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.4917     0.6918     0.9611\n",
      "      Rotation (45°)           0.2718     0.5713     0.9455\n",
      "      Scaling (1.5x)           0.4783     0.7267     1.0500\n",
      "      Fine Discrimination      0.4859     0.7422     0.9747\n",
      "      High Noise               0.4749     0.7128     0.9484\n",
      "      High Stress              0.4712     0.6267     0.9425\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.4676\n",
      "        50% Conflict: 0.4439\n",
      "        75% Conflict: 0.4105\n",
      "\n",
      "    [5] POST_TREATMENT - after_full_course\n",
      "    ------------------------------------------------------------\n",
      "      Stage: post_treatment | Treatment: ssri | after_full_course\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.5172     0.6689     0.9488\n",
      "      Rotation (45°)           0.2877     0.5179     0.9954\n",
      "      Scaling (1.5x)           0.5074     0.7079     1.0212\n",
      "      Fine Discrimination      0.5049     0.6950     0.9642\n",
      "      High Noise               0.5059     0.6892     1.0212\n",
      "      High Stress              0.5003     0.6255     0.9640\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.5006\n",
      "        50% Conflict: 0.4701\n",
      "        75% Conflict: 0.4372\n",
      "\n",
      "  NEUROSTEROID (Best config: strength=0.80)\n",
      "\n",
      "    ======================================================================\n",
      "    COGNITIVE TRAJECTORY: NEUROSTEROID\n",
      "    ======================================================================\n",
      "\n",
      "    [1] PRE_TREATMENT - before_medication\n",
      "    ------------------------------------------------------------\n",
      "      Stage: pre_treatment | Treatment: neurosteroid | before_medication\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3103     0.8478     0.9520\n",
      "      Rotation (45°)           0.2633     0.8493     0.9677\n",
      "      Scaling (1.5x)           0.3153     0.8843     1.0266\n",
      "      Fine Discrimination      0.3049     0.8798     1.0067\n",
      "      High Noise               0.3101     0.8632     0.9487\n",
      "      High Stress              0.3200     0.7975     0.9777\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.2933\n",
      "        50% Conflict: 0.2950\n",
      "        75% Conflict: 0.2802\n",
      "\n",
      "    [2] DURING_TREATMENT - immediate_medication_effect\n",
      "    ------------------------------------------------------------\n",
      "      Stage: during_treatment | Treatment: neurosteroid | immediate_medication_effect\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=0.80\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.3127     0.8387     0.9497\n",
      "      Rotation (45°)           0.2628     0.8339     0.9531\n",
      "      Scaling (1.5x)           0.3171     0.8802     1.0313\n",
      "      Fine Discrimination      0.3095     0.8757     0.9945\n",
      "      High Noise               0.3131     0.8653     0.9382\n",
      "      High Stress              0.3282     0.7527     0.9819\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.2989\n",
      "        50% Conflict: 0.2922\n",
      "        75% Conflict: 0.2876\n",
      "\n",
      "    [3] POST_TREATMENT - after_consolidation_on_med\n",
      "    ------------------------------------------------------------\n",
      "      Stage: post_treatment | Treatment: neurosteroid | after_consolidation_on_med\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=0.80\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.5525     0.6488     0.9850\n",
      "      Rotation (45°)           0.3155     0.4788     1.0689\n",
      "      Scaling (1.5x)           0.5584     0.6491     0.9716\n",
      "      Fine Discrimination      0.5256     0.6615     0.9847\n",
      "      High Noise               0.5486     0.6677     1.0586\n",
      "      High Stress              0.5243     0.5714     0.9908\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.5374\n",
      "        50% Conflict: 0.5042\n",
      "        75% Conflict: 0.4652\n",
      "\n",
      "    [4] OFF_MEDICATION - medication_discontinued\n",
      "    ------------------------------------------------------------\n",
      "      Stage: off_medication | Treatment: neurosteroid | medication_discontinued\n",
      "      Network State: Sparsity=95.0%, Stress=0.000, Inhibition=1.00\n",
      "      \n",
      "      Probe                  Accuracy     Persev       Flex\n",
      "      ----------------------------------------------------\n",
      "      Standard                 0.5492     0.6512     0.9785\n",
      "      Rotation (45°)           0.3029     0.4837     1.0308\n",
      "      Scaling (1.5x)           0.5472     0.6555     0.9777\n",
      "      Fine Discrimination      0.5347     0.6508     0.9432\n",
      "      High Noise               0.5440     0.6682     1.0500\n",
      "      High Stress              0.5354     0.6056     0.9518\n",
      "      \n",
      "      Sensory Integration (Blend Probes):\n",
      "        25% Conflict: 0.5341\n",
      "        50% Conflict: 0.5028\n",
      "        75% Conflict: 0.4607\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "                   COGNITIVE COMPARISON AT KEY ILLNESS STAGES                   \n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "------------------------------------------------------------\n",
      "  POST-TREATMENT COGNITIVE COMPARISON\n",
      "------------------------------------------------------------\n",
      "\n",
      "    Standard Task Performance:\n",
      "    Condition                Accuracy       Persev  Flexibility  Switch Cost\n",
      "    ----------------------------------------------------------------------\n",
      "    Healthy                    0.7598       0.2808       0.9604       0.0303\n",
      "    OCD Onset                  0.3103       0.8478       0.9520       0.0150\n",
      "    Ketamine                   0.3103       0.8478       0.9520       0.0150\n",
      "    SSRI                       0.5172       0.6689       0.9488       0.0267\n",
      "    Neurosteroid (on)          0.5525       0.6488       0.9850       0.0083\n",
      "    Neurosteroid (off)         0.5492       0.6512       0.9785       0.0118\n",
      "\n",
      "    Cognitive Probe Performance (Accuracy):\n",
      "    Condition              Rotation    Scaling  Fine Disc High Noise     Stress\n",
      "    ------------------------------------------------------------------------\n",
      "    Healthy                  0.5339     0.7655     0.7269     0.7602     0.7376\n",
      "    OCD Onset                0.2633     0.3153     0.3049     0.3101     0.3201\n",
      "    Ketamine                 0.2633     0.3153     0.3049     0.3101     0.3211\n",
      "    SSRI                     0.2877     0.5074     0.5049     0.5059     0.5003\n",
      "    Neurosteroid (on)        0.3155     0.5584     0.5256     0.5486     0.5243\n",
      "    Neurosteroid (off)       0.3029     0.5472     0.5347     0.5440     0.5354\n",
      "\n",
      "    Sensory Integration (Blend Probes):\n",
      "    Condition               Blend 25%    Blend 50%    Blend 75%\n",
      "    ----------------------------------------------------------\n",
      "    Healthy                    0.7160       0.6542       0.5904\n",
      "    OCD Onset                  0.2936       0.2932       0.2776\n",
      "    Ketamine                   0.2932       0.2867       0.2863\n",
      "    SSRI                       0.5006       0.4701       0.4372\n",
      "    Neurosteroid (on)          0.5374       0.5042       0.4652\n",
      "    Neurosteroid (off)         0.5341       0.5028       0.4607\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "                          COGNITIVE IMPACT OF RELAPSE                           \n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "    Pre-Relapse vs Post-Relapse Cognitive Comparison:\n",
      "    Treatment       Measure                  Pre-Relapse    Post-Relapse          Change\n",
      "    ----------------------------------------------------------------------------------\n",
      "    Ketamine        Std Accuracy                  0.7513          0.7251         -0.0262\n",
      "    Ketamine        Std Persev                    0.2725          0.2698         -0.0027\n",
      "    Ketamine        Rotation Acc                  0.4854          0.3410         -0.1444\n",
      "    Ketamine        Fine Disc Acc                 0.7106          0.6760         -0.0346\n",
      "    Ketamine        Blend 50%                     0.6608          0.6568         -0.0040\n",
      "    ----------------------------------------------------------------------------------\n",
      "    SSRI            Std Accuracy                  0.5172          0.3805         -0.1367\n",
      "    SSRI            Std Persev                    0.6689          0.8598         +0.1908\n",
      "    SSRI            Rotation Acc                  0.2877          0.3455         +0.0578\n",
      "    SSRI            Fine Disc Acc                 0.5049          0.3404         -0.1645\n",
      "    SSRI            Blend 50%                     0.4725          0.3716         -0.1009\n",
      "    ----------------------------------------------------------------------------------\n",
      "    Neurosteroid    Std Accuracy                  0.5525          0.4424         -0.1101\n",
      "    Neurosteroid    Std Persev                    0.6488          0.7917         +0.1429\n",
      "    Neurosteroid    Rotation Acc                  0.3155          0.3954         +0.0799\n",
      "    Neurosteroid    Fine Disc Acc                 0.5256          0.4184         -0.1072\n",
      "    Neurosteroid    Blend 50%                     0.5126          0.4269         -0.0857\n",
      "    ----------------------------------------------------------------------------------\n",
      "\n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "                         ISO-DOSE COGNITIVE COMPARISON                          \n",
      "════════════════════════════════════════════════════════════════════════════════\n",
      "\n",
      "  TARGET DOSE: 0.005000\n",
      "  ==========================================================================================\n",
      "\n",
      "  Treatment       Parameter               Dose L1  ΔSparsity   Acute Prsv   Rotation    Blend50\n",
      "  ------------------------------------------------------------------------------------------\n",
      "  Ketamine        regrow_fraction=0.1    0.004513     0.0946       0.3383     0.4064     0.6449\n",
      "  Ssri            epochs=200             0.001360     0.0000       0.6950     0.2877     0.4701\n",
      "  Neurosteroid    strength=0.5           0.002223     0.0000       0.6669     0.3024     0.5065\n",
      "\n",
      "  TARGET DOSE: 0.010000\n",
      "  ==========================================================================================\n",
      "\n",
      "  Treatment       Parameter               Dose L1  ΔSparsity   Acute Prsv   Rotation    Blend50\n",
      "  ------------------------------------------------------------------------------------------\n",
      "  Ketamine        regrow_fraction=0.5    0.010301     0.4733       0.2374     0.4801     0.6597\n",
      "  Ssri            epochs=200             0.001360     0.0000       0.6950     0.2877     0.4701\n",
      "  Neurosteroid    strength=0.5           0.002223     0.0000       0.6669     0.3024     0.5065\n",
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "                               EXPERIMENT SUMMARY                               \n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "\n",
      "  COGNITIVE TESTING THROUGHOUT ILLNESS COURSE:\n",
      "\n",
      "  1. BASELINE ASSESSMENTS:\n",
      "     - Healthy (fully trained, pre-pruning)\n",
      "     - OCD Onset (immediately post-pruning)\n",
      "\n",
      "  2. TREATMENT PHASES ASSESSED:\n",
      "     - Pre-treatment (untreated OCD state)\n",
      "     - During treatment (SSRI: multiple timepoints)\n",
      "     - Immediate medication effect (Neurosteroid)\n",
      "     - Post-treatment (all treatments)\n",
      "     - Off-medication (Neurosteroid)\n",
      "\n",
      "  3. RELAPSE SIMULATION:\n",
      "     - Pre-relapse cognitive state\n",
      "     - Post-relapse cognitive state\n",
      "     - Cognitive decline quantified\n",
      "\n",
      "  4. COGNITIVE DOMAINS TESTED:\n",
      "     - Standard task (rule-switching accuracy, perseveration, flexibility)\n",
      "     - Rotation probe (cognitive flexibility/generalization)\n",
      "     - Scaling probe (visuospatial processing)\n",
      "     - Fine discrimination (attention/perceptual acuity)\n",
      "     - High noise (distraction resistance)\n",
      "     - High stress (stress resilience)\n",
      "     - Sensory integration (conflicting stream blending at 25/50/75%)\n",
      "\n",
      "  5. ISO-DOSE COMPARISON:\n",
      "     - Fair comparison at matched network change levels\n",
      "     - Cognitive outcomes compared at equivalent \"doses\"\n",
      "    \n",
      "\n",
      "████████████████████████████████████████████████████████████████████████████████\n",
      "█                             EXPERIMENT COMPLETE                              █\n",
      "████████████████████████████████████████████████████████████████████████████████\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "================================================================================\n",
    "COMPUTATIONAL MODEL VALIDATING THE OCD SYNAPTIC PRUNING HYPOTHESIS\n",
    "WITH MULTI-MECHANISM ANTIDEPRESSANT COMPARISON\n",
    "+ COMPREHENSIVE COGNITIVE TESTING THROUGHOUT ILLNESS COURSE\n",
    "================================================================================\n",
    "\n",
    "This model extends the OCD framework to compare three distinct treatment mechanisms:\n",
    "- KETAMINE: Rapid structural repair via synaptogenesis\n",
    "- SSRI: Gradual functional stabilization with fixed structure\n",
    "- NEUROSTEROID: Rapid functional damping via tonic inhibition\n",
    "\n",
    "All mechanisms are modeled through network architecture modifications:\n",
    "- Weight masks / regrowth (structural changes)\n",
    "- Multiplicative scaling of hidden states (inhibition)\n",
    "- Activation functions (bounded vs unbounded)\n",
    "- Internal noise injection (stress/adaptation)\n",
    "- Training dynamics (fast vs slow, fixed vs dynamic weights)\n",
    "\n",
    "THEORETICAL FRAMEWORK:\n",
    "----------------------\n",
    "1. KETAMINE-LIKE: Rapid structural synaptogenesis + brief consolidation\n",
    "2. SSRI-LIKE: Functional stabilization via extended low-LR training + noise reduction\n",
    "3. NEUROSTEROID-LIKE: Tonic GABAergic inhibition (medication-dependent)\n",
    "\n",
    "KEY COMPARISONS:\n",
    "----------------\n",
    "- Acute effects: Immediate post-treatment symptom reduction\n",
    "- Long-term/relapse risk: Resistance to secondary pruning, off-medication reversal\n",
    "\n",
    "NEW IN VERSION 3.2 - COGNITIVE TESTING THROUGHOUT ILLNESS:\n",
    "----------------------------------------------------------\n",
    "- Cognitive battery evaluated at multiple illness stages:\n",
    "  * Healthy baseline (pre-illness)\n",
    "  * Post-pruning (OCD onset / untreated)\n",
    "  * During treatment (mid-treatment for SSRI)\n",
    "  * Post-treatment (acute response)\n",
    "  * During relapse simulation\n",
    "  * Off-medication (neurosteroid)\n",
    "- Domain-specific probes:\n",
    "  * Cognitive flexibility (rotation)\n",
    "  * Visuospatial processing (scaling)\n",
    "  * Fine discrimination / attention (compressed clusters)\n",
    "  * Distraction resistance (high noise)\n",
    "  * Sensory integration (conflicting streams)\n",
    "  * Stress resilience (high internal stress)\n",
    "- Iso-dose comparison preserved from v3.1\n",
    "\n",
    "Author: Computational Psychiatry Research\n",
    "Date: January 2026\n",
    "Version: 3.2 (Cognitive Testing Throughout Illness Course)\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Dict, Any, Union\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import copy\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Architecture Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'input_dim': 2,\n",
    "    'hidden_dims': [128, 64],\n",
    "    'output_dim': 4,\n",
    "    'num_gru_layers': 2,\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Training Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'batch_size': 32,\n",
    "    'baseline_lr': 1e-3,\n",
    "    'finetune_lr': 5e-4,\n",
    "    'baseline_epochs': 50,\n",
    "    'regrowth_epochs': 30,\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Sequence/Task Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'seq_len': 200,\n",
    "    'n_train_sequences': 500,\n",
    "    'n_test_sequences': 100,\n",
    "    'switch_interval': 50,\n",
    "    'n_rules': 4,\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Pruning Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'target_sparsities': [0.0, 0.5, 0.7, 0.85, 0.90, 0.93, 0.95, 0.97],\n",
    "    'regrowth_fraction': 0.50,\n",
    "    'regrowth_init_scale': 0.03,\n",
    "    'recurrence_bias': 1.2,\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Treatment Duration Experiment Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'consolidation_epochs': [0, 5, 10, 15, 20],\n",
    "    'relapse_prune_fraction': 0.40,\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Iterative Regimen Experiment Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'acute_regrow_fractions': [0.60, 1.00],\n",
    "    'chronic_cycles': [3, 6, 10],\n",
    "    'per_cycle_regrow': 0.40,\n",
    "    'per_cycle_epochs': 5,\n",
    "    'final_consolidation': 15,\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Stress/Noise Parameters\n",
    "    # -------------------------------------------------------------------------\n",
    "    'stress_levels': [0.0, 0.1, 0.3],\n",
    "    'glutamate_noise_levels': [0.0, 0.2, 0.5],\n",
    "    'relapse_noise': 0.2,\n",
    "\n",
    "    # =========================================================================\n",
    "    # MULTI-MECHANISM ANTIDEPRESSANT COMPARISON\n",
    "    # =========================================================================\n",
    "    'ocd_prune_sparsity': 0.95,\n",
    "    'comparison_ketamine_regrow': 0.60,\n",
    "    'comparison_ketamine_epochs': 10,\n",
    "    'comparison_ssri_epochs': 120,\n",
    "    'comparison_ssri_lr': 1e-5,\n",
    "    'comparison_ssri_initial_stress': 0.4,\n",
    "    'comparison_neurosteroid_strength': 0.65,\n",
    "    'comparison_neurosteroid_use_tanh': True,\n",
    "    'comparison_neurosteroid_epochs': 8,\n",
    "\n",
    "    # =========================================================================\n",
    "    # ISO-DOSE COMPARISON PARAMETERS\n",
    "    # =========================================================================\n",
    "    'iso_dose_norm_type': 'l1',\n",
    "    'iso_dose_target_doses': [0.005, 0.010, 0.020, 0.040],\n",
    "    'iso_dose_tolerance': 0.002,\n",
    "    'iso_dose_turnover_threshold': 0.10,\n",
    "\n",
    "    # Parameter sweep ranges\n",
    "    'ketamine_regrow_sweep': [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80],\n",
    "    'ssri_epochs_sweep': [20, 40, 60, 80, 100, 120, 160, 200],\n",
    "    'ssri_lr_sweep': [1e-6, 5e-6, 1e-5, 2e-5, 5e-5],\n",
    "    'neurosteroid_strength_sweep': [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85],\n",
    "\n",
    "    # =========================================================================\n",
    "    # COGNITIVE PROBE PARAMETERS (NEW)\n",
    "    # =========================================================================\n",
    "    'cognitive_rotation_deg': 45.0,\n",
    "    'cognitive_scale_factor': 1.5,\n",
    "    'cognitive_fine_disc_scale': 0.5,\n",
    "    'cognitive_fine_disc_noise': 0.8,\n",
    "    'cognitive_high_noise_level': 2.0,\n",
    "    'cognitive_high_stress_level': 0.5,\n",
    "    'cognitive_blend_ratios': [0.25, 0.50, 0.75],\n",
    "    'n_cognitive_test_sequences': 50,\n",
    "\n",
    "    # SSRI mid-treatment evaluation points (as fraction of total epochs)\n",
    "    'ssri_mid_eval_points': [0.25, 0.50, 0.75],\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Reproducibility\n",
    "    # -------------------------------------------------------------------------\n",
    "    'seed': 42,\n",
    "    'n_seeds': 3,\n",
    "}\n",
    "\n",
    "# Global device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Ensure reproducibility across runs.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def print_section_header(title: str, width: int = 80, char: str = \"=\"):\n",
    "    \"\"\"Print a formatted section header.\"\"\"\n",
    "    print(f\"\\n{char * width}\")\n",
    "    print(f\"{title.center(width)}\")\n",
    "    print(f\"{char * width}\")\n",
    "\n",
    "\n",
    "def print_subsection_header(title: str, width: int = 60, char: str = \"-\"):\n",
    "    \"\"\"Print a formatted subsection header.\"\"\"\n",
    "    print(f\"\\n{char * width}\")\n",
    "    print(f\"  {title}\")\n",
    "    print(f\"{char * width}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DOSING METRICS - MECHANISM-AGNOSTIC QUANTIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "def compute_weight_change_norm(\n",
    "    model_pre_state: Dict[str, torch.Tensor],\n",
    "    model_post: nn.Module,\n",
    "    norm_type: str = 'l1'\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute total weight change magnitude as mechanism-agnostic dose proxy.\n",
    "    Returns normalized dose (total change / total parameters).\n",
    "    \"\"\"\n",
    "    delta = 0.0\n",
    "    total_params = 0\n",
    "\n",
    "    for name, param in model_post.named_parameters():\n",
    "        if 'weight' in name and name in model_pre_state:\n",
    "            diff = (param.data - model_pre_state[name]).abs()\n",
    "            total_params += param.numel()\n",
    "            if norm_type == 'l1':\n",
    "                delta += diff.sum().item()\n",
    "            elif norm_type == 'l2':\n",
    "                delta += (diff ** 2).sum().item()\n",
    "\n",
    "    if norm_type == 'l2':\n",
    "        delta = delta ** 0.5\n",
    "\n",
    "    return delta / total_params if total_params > 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_synaptic_turnover(\n",
    "    model_pre_state: Dict[str, torch.Tensor],\n",
    "    model_post: nn.Module,\n",
    "    threshold: float = 0.10\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute fraction of synapses with significant weight changes.\n",
    "    Captures \"how many synapses were meaningfully modified\" (> threshold relative change).\n",
    "    \"\"\"\n",
    "    changed = 0\n",
    "    total = 0\n",
    "\n",
    "    for name, param in model_post.named_parameters():\n",
    "        if 'weight' in name and name in model_pre_state:\n",
    "            pre_weights = model_pre_state[name]\n",
    "            relative_change = (param.data - pre_weights).abs() / (pre_weights.abs().clamp(min=1e-8))\n",
    "            changed += (relative_change > threshold).sum().item()\n",
    "            total += param.numel()\n",
    "\n",
    "    return changed / total if total > 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_sparsity_change(\n",
    "    model_pre_state: Dict[str, torch.Tensor],\n",
    "    model_post: nn.Module\n",
    ") -> float:\n",
    "    \"\"\"Compute absolute change in network sparsity.\"\"\"\n",
    "    def get_sparsity(state_dict):\n",
    "        total = 0\n",
    "        zeros = 0\n",
    "        for name, tensor in state_dict.items():\n",
    "            if 'weight' in name:\n",
    "                total += tensor.numel()\n",
    "                zeros += (tensor.abs() < 1e-8).sum().item()\n",
    "        return zeros / total if total > 0 else 0.0\n",
    "\n",
    "    pre_sparsity = get_sparsity(model_pre_state)\n",
    "    post_sparsity = get_sparsity({n: p.data for n, p in model_post.named_parameters()})\n",
    "\n",
    "    return abs(post_sparsity - pre_sparsity)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DoseMetrics:\n",
    "    \"\"\"Container for all dosing quantification metrics.\"\"\"\n",
    "    l1_norm: float = 0.0\n",
    "    l2_norm: float = 0.0\n",
    "    synaptic_turnover: float = 0.0\n",
    "    sparsity_change: float = 0.0\n",
    "\n",
    "    @property\n",
    "    def primary_dose(self) -> float:\n",
    "        \"\"\"Primary dose metric (L1 norm by default).\"\"\"\n",
    "        return self.l1_norm\n",
    "\n",
    "\n",
    "def compute_all_dose_metrics(\n",
    "    model_pre_state: Dict[str, torch.Tensor],\n",
    "    model_post: nn.Module,\n",
    "    turnover_threshold: float = None\n",
    ") -> DoseMetrics:\n",
    "    \"\"\"Compute all dose quantification metrics.\"\"\"\n",
    "    if turnover_threshold is None:\n",
    "        turnover_threshold = CONFIG['iso_dose_turnover_threshold']\n",
    "\n",
    "    return DoseMetrics(\n",
    "        l1_norm=compute_weight_change_norm(model_pre_state, model_post, 'l1'),\n",
    "        l2_norm=compute_weight_change_norm(model_pre_state, model_post, 'l2'),\n",
    "        synaptic_turnover=compute_synaptic_turnover(model_pre_state, model_post, turnover_threshold),\n",
    "        sparsity_change=compute_sparsity_change(model_pre_state, model_post)\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RULE DEFINITIONS FOR COGNITIVE FLEXIBILITY TASK\n",
    "# =============================================================================\n",
    "\n",
    "class Rule(Enum):\n",
    "    \"\"\"Classification rules analogous to Wisconsin Card Sorting Test dimensions.\"\"\"\n",
    "    X_SIGN = 0\n",
    "    Y_SIGN = 1\n",
    "    QUADRANT = 2\n",
    "    DIAGONAL = 3\n",
    "\n",
    "\n",
    "def apply_rule(points: torch.Tensor, rule: int) -> torch.Tensor:\n",
    "    \"\"\"Apply a classification rule to 2D points.\"\"\"\n",
    "    x, y = points[..., 0], points[..., 1]\n",
    "\n",
    "    if rule == Rule.X_SIGN.value:\n",
    "        labels = ((x >= 0).long() * 2 + (y >= 0).long())\n",
    "    elif rule == Rule.Y_SIGN.value:\n",
    "        labels = ((y >= 0).long() * 2 + (x >= 0).long())\n",
    "    elif rule == Rule.QUADRANT.value:\n",
    "        labels = ((x >= 0).long() + (y >= 0).long() * 2)\n",
    "    elif rule == Rule.DIAGONAL.value:\n",
    "        main_diag = (y >= x).long()\n",
    "        anti_diag = (y >= -x).long()\n",
    "        labels = main_diag * 2 + anti_diag\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown rule: {rule}\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA GENERATION - STANDARD AND COGNITIVE PROBES\n",
    "# =============================================================================\n",
    "\n",
    "def generate_base_points(n_points: int, noise: float = 0.8) -> torch.Tensor:\n",
    "    \"\"\"Generate 2D points from 4 Gaussian clusters centered in each quadrant.\"\"\"\n",
    "    centers = torch.tensor([\n",
    "        [1.5, 1.5], [-1.5, 1.5], [-1.5, -1.5], [1.5, -1.5],\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    cluster_idx = torch.randint(0, 4, (n_points,))\n",
    "    points = centers[cluster_idx] + torch.randn(n_points, 2) * noise\n",
    "\n",
    "    return points\n",
    "\n",
    "\n",
    "def generate_rule_switch_sequences(\n",
    "    n_sequences: int,\n",
    "    seq_len: int,\n",
    "    switch_interval: int,\n",
    "    noise: float = 0.8,\n",
    "    deterministic_switches: bool = False\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate sequences with rule switches for cognitive flexibility testing.\"\"\"\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    all_rules = []\n",
    "\n",
    "    for _ in range(n_sequences):\n",
    "        points = generate_base_points(seq_len, noise=noise)\n",
    "        rules = torch.zeros(seq_len, dtype=torch.long)\n",
    "        current_rule = torch.randint(0, CONFIG['n_rules'], (1,)).item()\n",
    "\n",
    "        if deterministic_switches:\n",
    "            switch_points = set(range(switch_interval, seq_len, switch_interval))\n",
    "        else:\n",
    "            n_switches = max(1, seq_len // switch_interval)\n",
    "            valid_range = list(range(20, seq_len - 20))\n",
    "            if len(valid_range) >= n_switches:\n",
    "                switch_points = set(np.random.choice(\n",
    "                    valid_range, size=n_switches, replace=False\n",
    "                ))\n",
    "            else:\n",
    "                switch_points = set(valid_range)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            if t in switch_points:\n",
    "                new_rule = (current_rule + np.random.randint(1, CONFIG['n_rules'])) % CONFIG['n_rules']\n",
    "                current_rule = new_rule\n",
    "            rules[t] = current_rule\n",
    "\n",
    "        labels = torch.zeros(seq_len, dtype=torch.long)\n",
    "        for t in range(seq_len):\n",
    "            labels[t] = apply_rule(points[t:t+1], rules[t].item())[0]\n",
    "\n",
    "        all_data.append(points)\n",
    "        all_labels.append(labels)\n",
    "        all_rules.append(rules)\n",
    "\n",
    "    return torch.stack(all_data), torch.stack(all_labels), torch.stack(all_rules)\n",
    "\n",
    "\n",
    "def create_rule_switch_dataloaders(\n",
    "    n_train: int = None,\n",
    "    n_test: int = None,\n",
    "    seq_len: int = None,\n",
    "    batch_size: int = None\n",
    ") -> Tuple[DataLoader, DataLoader, torch.Tensor]:\n",
    "    \"\"\"Create train and test dataloaders for rule-switching task.\"\"\"\n",
    "    n_train = n_train or CONFIG['n_train_sequences']\n",
    "    n_test = n_test or CONFIG['n_test_sequences']\n",
    "    seq_len = seq_len or CONFIG['seq_len']\n",
    "    batch_size = batch_size or CONFIG['batch_size']\n",
    "\n",
    "    train_data, train_labels, train_rules = generate_rule_switch_sequences(\n",
    "        n_train, seq_len, CONFIG['switch_interval'], deterministic_switches=False\n",
    "    )\n",
    "    test_data, test_labels, test_rules = generate_rule_switch_sequences(\n",
    "        n_test, seq_len, CONFIG['switch_interval'], deterministic_switches=True\n",
    "    )\n",
    "\n",
    "    train_dataset = TensorDataset(train_data, train_labels, train_rules)\n",
    "    test_dataset = TensorDataset(test_data, test_labels, test_rules)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, test_rules\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# COGNITIVE PROBE DATA GENERATION (NEW)\n",
    "# =============================================================================\n",
    "\n",
    "def generate_rotated_sequences(\n",
    "    n_sequences: int,\n",
    "    seq_len: int,\n",
    "    switch_interval: int,\n",
    "    rotation_deg: float = 45.0,\n",
    "    noise: float = 0.8\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate rotated sequences for cognitive flexibility probe.\"\"\"\n",
    "    data, labels, rules = generate_rule_switch_sequences(\n",
    "        n_sequences, seq_len, switch_interval, noise=noise, deterministic_switches=True\n",
    "    )\n",
    "\n",
    "    # Apply rotation to all points\n",
    "    angle = math.radians(rotation_deg)\n",
    "    cos_a, sin_a = math.cos(angle), math.sin(angle)\n",
    "    rot_matrix = torch.tensor([[cos_a, -sin_a], [sin_a, cos_a]], dtype=torch.float32)\n",
    "\n",
    "    # data shape: [n_sequences, seq_len, 2]\n",
    "    rotated_data = torch.einsum('nsi,ij->nsj', data, rot_matrix)\n",
    "\n",
    "    return rotated_data, labels, rules\n",
    "\n",
    "\n",
    "def generate_scaled_sequences(\n",
    "    n_sequences: int,\n",
    "    seq_len: int,\n",
    "    switch_interval: int,\n",
    "    scale_factor: float = 1.5,\n",
    "    noise: float = 0.8\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate scaled sequences for visuospatial processing probe.\"\"\"\n",
    "    data, labels, rules = generate_rule_switch_sequences(\n",
    "        n_sequences, seq_len, switch_interval, noise=noise, deterministic_switches=True\n",
    "    )\n",
    "    scaled_data = data * scale_factor\n",
    "    return scaled_data, labels, rules\n",
    "\n",
    "\n",
    "def generate_fine_discrimination_sequences(\n",
    "    n_sequences: int,\n",
    "    seq_len: int,\n",
    "    switch_interval: int,\n",
    "    center_scale: float = 0.5,\n",
    "    noise: float = 0.8\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate compressed cluster sequences for fine discrimination / attention probe.\"\"\"\n",
    "    # Generate with compressed centers\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    all_rules = []\n",
    "\n",
    "    centers = torch.tensor([\n",
    "        [1.5, 1.5], [-1.5, 1.5], [-1.5, -1.5], [1.5, -1.5],\n",
    "    ], dtype=torch.float32) * center_scale\n",
    "\n",
    "    for _ in range(n_sequences):\n",
    "        cluster_idx = torch.randint(0, 4, (seq_len,))\n",
    "        points = centers[cluster_idx] + torch.randn(seq_len, 2) * noise\n",
    "\n",
    "        rules = torch.zeros(seq_len, dtype=torch.long)\n",
    "        current_rule = torch.randint(0, CONFIG['n_rules'], (1,)).item()\n",
    "\n",
    "        switch_points = set(range(switch_interval, seq_len, switch_interval))\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            if t in switch_points:\n",
    "                new_rule = (current_rule + np.random.randint(1, CONFIG['n_rules'])) % CONFIG['n_rules']\n",
    "                current_rule = new_rule\n",
    "            rules[t] = current_rule\n",
    "\n",
    "        labels = torch.zeros(seq_len, dtype=torch.long)\n",
    "        for t in range(seq_len):\n",
    "            labels[t] = apply_rule(points[t:t+1], rules[t].item())[0]\n",
    "\n",
    "        all_data.append(points)\n",
    "        all_labels.append(labels)\n",
    "        all_rules.append(rules)\n",
    "\n",
    "    return torch.stack(all_data), torch.stack(all_labels), torch.stack(all_rules)\n",
    "\n",
    "\n",
    "def generate_high_noise_sequences(\n",
    "    n_sequences: int,\n",
    "    seq_len: int,\n",
    "    switch_interval: int,\n",
    "    noise: float = 2.0\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate high-noise sequences for distraction resistance probe.\"\"\"\n",
    "    return generate_rule_switch_sequences(\n",
    "        n_sequences, seq_len, switch_interval, noise=noise, deterministic_switches=True\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_conflicting_sequences(\n",
    "    n_sequences: int,\n",
    "    seq_len: int,\n",
    "    switch_interval: int,\n",
    "    noise: float = 0.8\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Generate sequences with conflicting 'voice' labels for sensory integration probe.\"\"\"\n",
    "    data, visual_labels, rules = generate_rule_switch_sequences(\n",
    "        n_sequences, seq_len, switch_interval, noise=noise, deterministic_switches=True\n",
    "    )\n",
    "\n",
    "    # Create conflicting labels (permuted)\n",
    "    permutation = torch.tensor([2, 3, 0, 1])  # Swap quadrants diagonally\n",
    "    conflicting_labels = permutation[visual_labels]\n",
    "\n",
    "    return data, visual_labels, conflicting_labels, rules\n",
    "\n",
    "\n",
    "def create_cognitive_probe_loaders(\n",
    "    n_sequences: int = None,\n",
    "    seq_len: int = None,\n",
    "    batch_size: int = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Create all cognitive probe dataloaders.\"\"\"\n",
    "    n_sequences = n_sequences or CONFIG['n_cognitive_test_sequences']\n",
    "    seq_len = seq_len or CONFIG['seq_len']\n",
    "    batch_size = batch_size or CONFIG['batch_size']\n",
    "    switch_interval = CONFIG['switch_interval']\n",
    "\n",
    "    probes = {}\n",
    "\n",
    "    # Standard test (baseline reference)\n",
    "    std_data, std_labels, std_rules = generate_rule_switch_sequences(\n",
    "        n_sequences, seq_len, switch_interval, noise=0.8, deterministic_switches=True\n",
    "    )\n",
    "    probes['standard'] = DataLoader(\n",
    "        TensorDataset(std_data, std_labels, std_rules),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Rotation probe (cognitive flexibility)\n",
    "    rot_data, rot_labels, rot_rules = generate_rotated_sequences(\n",
    "        n_sequences, seq_len, switch_interval,\n",
    "        rotation_deg=CONFIG['cognitive_rotation_deg']\n",
    "    )\n",
    "    probes['rotation'] = DataLoader(\n",
    "        TensorDataset(rot_data, rot_labels, rot_rules),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Scaling probe (visuospatial processing)\n",
    "    scale_data, scale_labels, scale_rules = generate_scaled_sequences(\n",
    "        n_sequences, seq_len, switch_interval,\n",
    "        scale_factor=CONFIG['cognitive_scale_factor']\n",
    "    )\n",
    "    probes['scaling'] = DataLoader(\n",
    "        TensorDataset(scale_data, scale_labels, scale_rules),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Fine discrimination probe (attention / perceptual acuity)\n",
    "    fine_data, fine_labels, fine_rules = generate_fine_discrimination_sequences(\n",
    "        n_sequences, seq_len, switch_interval,\n",
    "        center_scale=CONFIG['cognitive_fine_disc_scale'],\n",
    "        noise=CONFIG['cognitive_fine_disc_noise']\n",
    "    )\n",
    "    probes['fine_discrimination'] = DataLoader(\n",
    "        TensorDataset(fine_data, fine_labels, fine_rules),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # High noise probe (distraction resistance)\n",
    "    noise_data, noise_labels, noise_rules = generate_high_noise_sequences(\n",
    "        n_sequences, seq_len, switch_interval,\n",
    "        noise=CONFIG['cognitive_high_noise_level']\n",
    "    )\n",
    "    probes['high_noise'] = DataLoader(\n",
    "        TensorDataset(noise_data, noise_labels, noise_rules),\n",
    "        batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Conflicting streams for blend probes (sensory integration)\n",
    "    conf_data, conf_visual, conf_voice, conf_rules = generate_conflicting_sequences(\n",
    "        n_sequences, seq_len, switch_interval\n",
    "    )\n",
    "    probes['conflict_data'] = conf_data\n",
    "    probes['conflict_visual_labels'] = conf_visual\n",
    "    probes['conflict_voice_labels'] = conf_voice\n",
    "    probes['conflict_rules'] = conf_rules\n",
    "\n",
    "    return probes\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RECURRENT NETWORK ARCHITECTURE (CSTC LOOP MODEL) - ENHANCED\n",
    "# =============================================================================\n",
    "\n",
    "class CSTCNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Recurrent network modeling cortico-striato-thalamo-cortical (CSTC) loops.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dims: List[int] = None, num_layers: int = None):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = CONFIG['hidden_dims']\n",
    "        if num_layers is None:\n",
    "            num_layers = CONFIG['num_gru_layers']\n",
    "\n",
    "        self.hidden_dim = hidden_dims[1]\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.input_fc = nn.Linear(CONFIG['input_dim'], hidden_dims[0])\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=hidden_dims[0],\n",
    "            hidden_size=hidden_dims[1],\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.1 if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.output_fc = nn.Linear(hidden_dims[1], CONFIG['output_dim'])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.stress_level = 0.0\n",
    "        self.glutamate_noise = 0.0\n",
    "\n",
    "        self.inhibition_strength = 1.0\n",
    "        self.use_tanh = False\n",
    "\n",
    "        self.register_buffer('input_mask', torch.ones_like(self.input_fc.weight))\n",
    "        self.register_buffer('output_mask', torch.ones_like(self.output_fc.weight))\n",
    "        self.gru_masks = {}\n",
    "\n",
    "    def init_hidden(self, batch_size: int, device: torch.device) -> torch.Tensor:\n",
    "        \"\"\"Initialize GRU hidden state.\"\"\"\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "\n",
    "    def set_inhibition(self, strength: float, use_tanh: bool = False):\n",
    "        \"\"\"Apply neurosteroid-like tonic inhibition.\"\"\"\n",
    "        self.inhibition_strength = max(0.0, min(1.0, strength))\n",
    "        self.use_tanh = use_tanh\n",
    "\n",
    "    def reduce_stress_gradually(self, epoch: int, total_epochs: int,\n",
    "                                initial_stress: float = 0.4, final_stress: float = 0.0):\n",
    "        \"\"\"SSRI-like: Linearly reduce internal recurrent noise over epochs.\"\"\"\n",
    "        progress = epoch / max(total_epochs - 1, 1)\n",
    "        self.stress_level = initial_stress + progress * (final_stress - initial_stress)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        hidden: Optional[torch.Tensor] = None,\n",
    "        return_hidden: bool = False\n",
    "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        \"\"\"Forward pass through CSTC network.\"\"\"\n",
    "        single_step = x.dim() == 2\n",
    "        if single_step:\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        device = x.device\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size, device)\n",
    "\n",
    "        if self.glutamate_noise > 0:\n",
    "            x = x + torch.randn_like(x) * self.glutamate_noise\n",
    "\n",
    "        masked_weight = self.input_fc.weight * self.input_mask\n",
    "        h = F.linear(x, masked_weight, self.input_fc.bias)\n",
    "        h = self.relu(h)\n",
    "\n",
    "        h = h * self.inhibition_strength\n",
    "\n",
    "        if self.stress_level > 0:\n",
    "            h = h + torch.randn_like(h) * self.stress_level\n",
    "\n",
    "        gru_out, hidden = self.gru(h, hidden)\n",
    "\n",
    "        gru_out = gru_out * self.inhibition_strength\n",
    "        if self.use_tanh:\n",
    "            gru_out = torch.tanh(gru_out)\n",
    "\n",
    "        if self.stress_level > 0:\n",
    "            gru_out = gru_out + torch.randn_like(gru_out) * self.stress_level * 0.5\n",
    "\n",
    "        masked_output_weight = self.output_fc.weight * self.output_mask\n",
    "        logits = F.linear(gru_out, masked_output_weight, self.output_fc.bias)\n",
    "\n",
    "        if single_step:\n",
    "            logits = logits.squeeze(1)\n",
    "\n",
    "        if return_hidden:\n",
    "            return logits, hidden\n",
    "        return logits, None\n",
    "\n",
    "    def set_stress(self, level: float):\n",
    "        \"\"\"Set internal noise level.\"\"\"\n",
    "        self.stress_level = max(0.0, level)\n",
    "\n",
    "    def set_glutamate_noise(self, level: float):\n",
    "        \"\"\"Set input-only noise for glutamate independence testing.\"\"\"\n",
    "        self.glutamate_noise = max(0.0, level)\n",
    "\n",
    "    def get_sparsity(self) -> float:\n",
    "        \"\"\"Calculate current network sparsity.\"\"\"\n",
    "        total_params = 0\n",
    "        zero_params = 0\n",
    "\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                total_params += param.numel()\n",
    "                zero_params += (param.abs() < 1e-8).sum().item()\n",
    "\n",
    "        return zero_params / total_params if total_params > 0 else 0.0\n",
    "\n",
    "    def get_treatment_state(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get current treatment-related state for logging.\"\"\"\n",
    "        return {\n",
    "            'stress_level': self.stress_level,\n",
    "            'glutamate_noise': self.glutamate_noise,\n",
    "            'inhibition_strength': self.inhibition_strength,\n",
    "            'use_tanh': self.use_tanh,\n",
    "            'sparsity': self.get_sparsity()\n",
    "        }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PRUNING MANAGER WITH TREATMENT SIMULATION CAPABILITIES\n",
    "# =============================================================================\n",
    "\n",
    "class CSTCPruningManager:\n",
    "    \"\"\"Manages pruning, regrowth, and relapse simulation for CSTC networks.\"\"\"\n",
    "\n",
    "    def __init__(self, model: CSTCNetwork):\n",
    "        self.model = model\n",
    "        self.original_weights = {}\n",
    "        self.masks = {}\n",
    "        self.history = []\n",
    "        self._save_original_weights()\n",
    "\n",
    "    def _save_original_weights(self):\n",
    "        \"\"\"Store original weights for regrowth restoration.\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                self.original_weights[name] = param.data.clone()\n",
    "                self.masks[name] = torch.ones_like(param.data)\n",
    "\n",
    "    def get_sparsity(self) -> float:\n",
    "        \"\"\"Get current network sparsity.\"\"\"\n",
    "        return self.model.get_sparsity()\n",
    "\n",
    "    def prune_by_magnitude(\n",
    "        self,\n",
    "        sparsity: float,\n",
    "        recurrence_bias: float = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Apply global magnitude-based pruning.\"\"\"\n",
    "        if recurrence_bias is None:\n",
    "            recurrence_bias = CONFIG['recurrence_bias']\n",
    "\n",
    "        if sparsity <= 0:\n",
    "            return {'achieved_sparsity': 0.0, 'weights_pruned': 0}\n",
    "\n",
    "        all_weights = []\n",
    "        weight_info = []\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'weight' in name and param.requires_grad:\n",
    "                flat_weights = param.data.abs().flatten()\n",
    "\n",
    "                if 'gru' in name and recurrence_bias != 1.0:\n",
    "                    flat_weights = flat_weights / recurrence_bias\n",
    "\n",
    "                all_weights.append(flat_weights)\n",
    "                weight_info.append((name, param))\n",
    "\n",
    "        if not all_weights:\n",
    "            return {'achieved_sparsity': 0.0, 'weights_pruned': 0}\n",
    "\n",
    "        all_weights_cat = torch.cat(all_weights)\n",
    "        k = int(sparsity * all_weights_cat.numel())\n",
    "        if k == 0:\n",
    "            return {'achieved_sparsity': 0.0, 'weights_pruned': 0}\n",
    "\n",
    "        threshold = torch.kthvalue(all_weights_cat, k).values.item()\n",
    "\n",
    "        total_pruned = 0\n",
    "        layer_stats = {}\n",
    "\n",
    "        for name, param in weight_info:\n",
    "            effective_weights = param.data.abs()\n",
    "            if 'gru' in name and recurrence_bias != 1.0:\n",
    "                effective_weights = effective_weights / recurrence_bias\n",
    "\n",
    "            mask = (effective_weights > threshold).float()\n",
    "            pruned_count = (mask == 0).sum().item()\n",
    "\n",
    "            self.masks[name] = mask\n",
    "            param.data *= mask\n",
    "\n",
    "            total_pruned += pruned_count\n",
    "            layer_stats[name] = {\n",
    "                'pruned': pruned_count,\n",
    "                'total': param.numel(),\n",
    "                'layer_sparsity': pruned_count / param.numel()\n",
    "            }\n",
    "\n",
    "            if name == 'input_fc.weight':\n",
    "                self.model.input_mask.copy_(mask)\n",
    "            elif name == 'output_fc.weight':\n",
    "                self.model.output_mask.copy_(mask)\n",
    "\n",
    "        achieved = self.get_sparsity()\n",
    "\n",
    "        self.history.append({\n",
    "            'operation': 'prune_magnitude',\n",
    "            'target_sparsity': sparsity,\n",
    "            'achieved_sparsity': achieved,\n",
    "            'weights_pruned': total_pruned,\n",
    "            'recurrence_bias': recurrence_bias\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'achieved_sparsity': achieved,\n",
    "            'weights_pruned': total_pruned,\n",
    "            'layer_stats': layer_stats\n",
    "        }\n",
    "\n",
    "    def gradient_guided_regrow(\n",
    "        self,\n",
    "        train_loader: DataLoader = None,\n",
    "        regrow_fraction: float = None,\n",
    "        n_batches: int = 5,\n",
    "        init_scale: float = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Regrow connections guided by gradient importance.\"\"\"\n",
    "        if regrow_fraction is None:\n",
    "            regrow_fraction = CONFIG['regrowth_fraction']\n",
    "        if init_scale is None:\n",
    "            init_scale = CONFIG['regrowth_init_scale']\n",
    "        if train_loader is None:\n",
    "            train_loader, _, _ = create_rule_switch_dataloaders()\n",
    "\n",
    "        self.model.train()\n",
    "        device = next(self.model.parameters()).device\n",
    "\n",
    "        gradient_importance = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                gradient_importance[name] = torch.zeros_like(param.data)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for batch_idx, (data, labels, _) in enumerate(train_loader):\n",
    "            if batch_idx >= n_batches:\n",
    "                break\n",
    "\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            self.model.zero_grad()\n",
    "\n",
    "            logits, _ = self.model(data)\n",
    "            loss = criterion(logits.view(-1, CONFIG['output_dim']), labels.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if 'weight' in name and param.grad is not None:\n",
    "                    gradient_importance[name] += param.grad.abs()\n",
    "\n",
    "        total_regrown = 0\n",
    "        layer_stats = {}\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'weight' not in name:\n",
    "                continue\n",
    "\n",
    "            mask = self.masks.get(name, torch.ones_like(param.data))\n",
    "            pruned_mask = (mask < 0.5)\n",
    "\n",
    "            if pruned_mask.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            n_regrow = int(regrow_fraction * pruned_mask.sum().item())\n",
    "            if n_regrow == 0:\n",
    "                continue\n",
    "\n",
    "            importance = gradient_importance[name] * pruned_mask.float()\n",
    "            flat_importance = importance.flatten()\n",
    "            n_positive = (flat_importance > 0).sum().item()\n",
    "\n",
    "            if n_positive == 0:\n",
    "                continue\n",
    "\n",
    "            _, top_indices = torch.topk(flat_importance, min(n_regrow, n_positive))\n",
    "\n",
    "            flat_mask = mask.flatten()\n",
    "            flat_param = param.data.flatten()\n",
    "            flat_original = self.original_weights[name].flatten()\n",
    "\n",
    "            for idx in top_indices:\n",
    "                flat_mask[idx] = 1.0\n",
    "                flat_param[idx] = flat_original[idx] * init_scale\n",
    "\n",
    "            new_mask = flat_mask.view_as(mask)\n",
    "            param.data = flat_param.view_as(param.data)\n",
    "            self.masks[name] = new_mask\n",
    "\n",
    "            if name == 'input_fc.weight':\n",
    "                self.model.input_mask.copy_(new_mask)\n",
    "            elif name == 'output_fc.weight':\n",
    "                self.model.output_mask.copy_(new_mask)\n",
    "\n",
    "            regrown_count = len(top_indices)\n",
    "            total_regrown += regrown_count\n",
    "            layer_stats[name] = {\n",
    "                'regrown': regrown_count,\n",
    "                'remaining_pruned': pruned_mask.sum().item() - regrown_count\n",
    "            }\n",
    "\n",
    "        new_sparsity = self.get_sparsity()\n",
    "\n",
    "        self.history.append({\n",
    "            'operation': 'gradient_regrow',\n",
    "            'regrow_fraction': regrow_fraction,\n",
    "            'connections_regrown': total_regrown,\n",
    "            'new_sparsity': new_sparsity\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'connections_regrown': total_regrown,\n",
    "            'new_sparsity': new_sparsity,\n",
    "            'layer_stats': layer_stats\n",
    "        }\n",
    "\n",
    "    def secondary_prune(\n",
    "        self,\n",
    "        fraction: float,\n",
    "        bias_recurrent: bool = False,\n",
    "        recurrence_multiplier: float = 1.5\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Simulate relapse by pruning a fraction of surviving weights.\"\"\"\n",
    "        stats = {}\n",
    "        total_pruned = 0\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name not in self.masks:\n",
    "                continue\n",
    "\n",
    "            mask = self.masks[name]\n",
    "            active_positions = (mask == 1)\n",
    "            n_active = active_positions.sum().item()\n",
    "\n",
    "            if n_active == 0:\n",
    "                continue\n",
    "\n",
    "            effective_fraction = fraction\n",
    "            if bias_recurrent and 'gru' in name:\n",
    "                effective_fraction = min(fraction * recurrence_multiplier, 0.9)\n",
    "\n",
    "            num_to_prune = int(effective_fraction * n_active)\n",
    "            if num_to_prune == 0:\n",
    "                continue\n",
    "\n",
    "            weights = param.data.abs()\n",
    "            weights_active = weights.clone()\n",
    "            weights_active[~active_positions] = float('inf')\n",
    "\n",
    "            flat_weights = weights_active.flatten()\n",
    "            threshold = torch.kthvalue(flat_weights, num_to_prune).values.item()\n",
    "\n",
    "            prune_mask = (weights <= threshold) & active_positions\n",
    "            mask[prune_mask] = 0\n",
    "            param.data[prune_mask] = 0\n",
    "\n",
    "            pruned_count = prune_mask.sum().item()\n",
    "            total_pruned += pruned_count\n",
    "\n",
    "            stats[name] = {\n",
    "                'pruned': pruned_count,\n",
    "                'remaining': n_active - pruned_count,\n",
    "                'effective_fraction': effective_fraction\n",
    "            }\n",
    "\n",
    "            if name == 'input_fc.weight':\n",
    "                self.model.input_mask.copy_(mask)\n",
    "            elif name == 'output_fc.weight':\n",
    "                self.model.output_mask.copy_(mask)\n",
    "\n",
    "        new_sparsity = self.get_sparsity()\n",
    "\n",
    "        self.history.append({\n",
    "            'operation': 'secondary_prune',\n",
    "            'fraction': fraction,\n",
    "            'bias_recurrent': bias_recurrent,\n",
    "            'total_pruned': total_pruned,\n",
    "            'new_sparsity': new_sparsity\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'total_pruned': total_pruned,\n",
    "            'new_sparsity': new_sparsity,\n",
    "            'layer_stats': stats\n",
    "        }\n",
    "\n",
    "    def apply_masks(self):\n",
    "        \"\"\"Re-apply masks after training steps to maintain sparsity pattern.\"\"\"\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.masks:\n",
    "                param.data *= self.masks[name]\n",
    "\n",
    "    def get_history_summary(self) -> str:\n",
    "        \"\"\"Get a formatted summary of all operations.\"\"\"\n",
    "        lines = [\"Pruning Manager History:\"]\n",
    "        for i, op in enumerate(self.history):\n",
    "            lines.append(f\"  {i+1}. {op['operation']}: {op}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# OCD-SPECIFIC EVALUATION METRICS\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class OCDMetrics:\n",
    "    \"\"\"Metrics capturing OCD-relevant behavioral phenotypes.\"\"\"\n",
    "\n",
    "    accuracy: float = 0.0\n",
    "    perseverative_error_rate: float = 0.0\n",
    "    switch_cost: float = 0.0\n",
    "    trials_to_recover: float = 0.0\n",
    "    repetition_rate: float = 0.0\n",
    "    repetition_entropy: float = 0.0\n",
    "    output_diversity: float = 0.0\n",
    "    rule_inference_accuracy: float = 0.0\n",
    "    flexibility_index: float = 0.0\n",
    "    sparsity: float = 0.0\n",
    "    stress_level: float = 0.0\n",
    "    glutamate_noise: float = 0.0\n",
    "    inhibition_strength: float = 1.0\n",
    "    use_tanh: bool = False\n",
    "\n",
    "\n",
    "def compute_ocd_metrics(\n",
    "    model: CSTCNetwork,\n",
    "    test_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    detailed: bool = False\n",
    ") -> OCDMetrics:\n",
    "    \"\"\"Compute comprehensive OCD-relevant metrics.\"\"\"\n",
    "    model.eval()\n",
    "    metrics = OCDMetrics()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_rules = []\n",
    "    all_correct = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels, rules in test_loader:\n",
    "            data, labels, rules = data.to(device), labels.to(device), rules.to(device)\n",
    "\n",
    "            batch_size, seq_len, _ = data.shape\n",
    "            hidden = model.init_hidden(batch_size, device)\n",
    "\n",
    "            batch_preds = []\n",
    "            for t in range(seq_len):\n",
    "                logits, hidden = model(data[:, t:t+1, :], hidden, return_hidden=True)\n",
    "                preds = logits.squeeze(1).argmax(dim=-1)\n",
    "                batch_preds.append(preds)\n",
    "\n",
    "            batch_preds = torch.stack(batch_preds, dim=1)\n",
    "\n",
    "            all_predictions.append(batch_preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_rules.append(rules.cpu())\n",
    "            all_correct.append((batch_preds == labels).cpu())\n",
    "\n",
    "    predictions = torch.cat(all_predictions, dim=0)\n",
    "    labels = torch.cat(all_labels, dim=0)\n",
    "    rules = torch.cat(all_rules, dim=0)\n",
    "    correct = torch.cat(all_correct, dim=0)\n",
    "\n",
    "    n_sequences, seq_len = predictions.shape\n",
    "\n",
    "    metrics.accuracy = correct.float().mean().item()\n",
    "\n",
    "    rule_changes = (rules[:, 1:] != rules[:, :-1])\n",
    "\n",
    "    perseverative_errors = 0\n",
    "    perseverative_opportunities = 0\n",
    "    switch_accuracies = []\n",
    "    stable_accuracies = []\n",
    "    recovery_trials_list = []\n",
    "\n",
    "    for seq_idx in range(n_sequences):\n",
    "        switch_points = torch.where(rule_changes[seq_idx])[0] + 1\n",
    "\n",
    "        prev_switch = 0\n",
    "        for switch_t in switch_points:\n",
    "            switch_t = switch_t.item()\n",
    "            if switch_t - prev_switch >= 10:\n",
    "                stable_acc = correct[seq_idx, prev_switch+5:switch_t-5].float().mean().item()\n",
    "                if not np.isnan(stable_acc):\n",
    "                    stable_accuracies.append(stable_acc)\n",
    "            prev_switch = switch_t\n",
    "\n",
    "        for switch_t in switch_points:\n",
    "            switch_t = switch_t.item()\n",
    "            if switch_t >= seq_len - 10:\n",
    "                continue\n",
    "\n",
    "            window_end = min(switch_t + 10, seq_len)\n",
    "            for t in range(switch_t, window_end):\n",
    "                if not correct[seq_idx, t]:\n",
    "                    perseverative_opportunities += 1\n",
    "                    if t > 0 and predictions[seq_idx, t] == predictions[seq_idx, t-1]:\n",
    "                        perseverative_errors += 1\n",
    "\n",
    "            post_acc = correct[seq_idx, switch_t:min(switch_t+5, seq_len)].float().mean().item()\n",
    "\n",
    "            if not np.isnan(post_acc):\n",
    "                switch_accuracies.append(post_acc)\n",
    "\n",
    "            for recovery_t in range(switch_t, min(seq_len - 5, switch_t + 50)):\n",
    "                window_acc = correct[seq_idx, recovery_t:recovery_t+5].float().mean().item()\n",
    "                if window_acc >= 0.8:\n",
    "                    recovery_trials_list.append(recovery_t - switch_t)\n",
    "                    break\n",
    "            else:\n",
    "                recovery_trials_list.append(50)\n",
    "\n",
    "    if perseverative_opportunities > 0:\n",
    "        metrics.perseverative_error_rate = perseverative_errors / perseverative_opportunities\n",
    "\n",
    "    if switch_accuracies and stable_accuracies:\n",
    "        metrics.switch_cost = np.mean(stable_accuracies) - np.mean(switch_accuracies)\n",
    "        metrics.flexibility_index = np.mean(switch_accuracies) / (np.mean(stable_accuracies) + 1e-8)\n",
    "\n",
    "    if recovery_trials_list:\n",
    "        metrics.trials_to_recover = np.mean(recovery_trials_list)\n",
    "\n",
    "    if stable_accuracies:\n",
    "        metrics.rule_inference_accuracy = np.mean(stable_accuracies)\n",
    "\n",
    "    repetitions = (predictions[:, 1:] == predictions[:, :-1]).float()\n",
    "    metrics.repetition_rate = repetitions.mean().item()\n",
    "\n",
    "    output_counts = torch.bincount(predictions.flatten(), minlength=CONFIG['output_dim']).float()\n",
    "    output_probs = output_counts / output_counts.sum()\n",
    "    entropy = -(output_probs * torch.log(output_probs + 1e-8)).sum().item()\n",
    "    max_entropy = np.log(CONFIG['output_dim'])\n",
    "    metrics.repetition_entropy = entropy\n",
    "    metrics.output_diversity = entropy / max_entropy\n",
    "\n",
    "    metrics.sparsity = model.get_sparsity()\n",
    "    metrics.stress_level = model.stress_level\n",
    "    metrics.glutamate_noise = model.glutamate_noise\n",
    "    metrics.inhibition_strength = model.inhibition_strength\n",
    "    metrics.use_tanh = model.use_tanh\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# COMPREHENSIVE COGNITIVE EVALUATION (NEW)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class CognitiveProbeResults:\n",
    "    \"\"\"Results from a single cognitive probe evaluation.\"\"\"\n",
    "    probe_name: str\n",
    "    accuracy: float\n",
    "    perseverative_error_rate: float\n",
    "    flexibility_index: float\n",
    "    switch_cost: float\n",
    "    trials_to_recover: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ComprehensiveCognitiveResults:\n",
    "    \"\"\"Full cognitive battery results at a single timepoint.\"\"\"\n",
    "    stage: str  # e.g., \"healthy_baseline\", \"post_pruning\", \"post_treatment\", etc.\n",
    "    treatment: str  # e.g., \"ketamine\", \"ssri\", \"neurosteroid\", \"untreated\"\n",
    "    timepoint_detail: str  # Additional detail (e.g., \"epoch_60\" for SSRI mid-treatment)\n",
    "    sparsity: float\n",
    "    stress_level: float\n",
    "    inhibition_strength: float\n",
    "\n",
    "    # Standard task performance\n",
    "    standard_accuracy: float\n",
    "    standard_persev: float\n",
    "    standard_flex: float\n",
    "    standard_switch_cost: float\n",
    "    standard_recovery: float\n",
    "\n",
    "    # Cognitive probes\n",
    "    rotation_accuracy: float = 0.0\n",
    "    rotation_persev: float = 0.0\n",
    "    rotation_flex: float = 0.0\n",
    "\n",
    "    scaling_accuracy: float = 0.0\n",
    "    scaling_persev: float = 0.0\n",
    "    scaling_flex: float = 0.0\n",
    "\n",
    "    fine_disc_accuracy: float = 0.0\n",
    "    fine_disc_persev: float = 0.0\n",
    "    fine_disc_flex: float = 0.0\n",
    "\n",
    "    high_noise_accuracy: float = 0.0\n",
    "    high_noise_persev: float = 0.0\n",
    "    high_noise_flex: float = 0.0\n",
    "\n",
    "    high_stress_accuracy: float = 0.0\n",
    "    high_stress_persev: float = 0.0\n",
    "    high_stress_flex: float = 0.0\n",
    "\n",
    "    # Sensory integration (blend probes)\n",
    "    blend_25_accuracy: float = 0.0\n",
    "    blend_50_accuracy: float = 0.0\n",
    "    blend_75_accuracy: float = 0.0\n",
    "\n",
    "\n",
    "def evaluate_cognitive_probe(\n",
    "    model: CSTCNetwork,\n",
    "    probe_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    apply_stress: float = 0.0\n",
    ") -> CognitiveProbeResults:\n",
    "    \"\"\"Evaluate model on a single cognitive probe.\"\"\"\n",
    "    original_stress = model.stress_level\n",
    "    if apply_stress > 0:\n",
    "        model.set_stress(apply_stress)\n",
    "\n",
    "    metrics = compute_ocd_metrics(model, probe_loader, device)\n",
    "\n",
    "    model.set_stress(original_stress)\n",
    "\n",
    "    return CognitiveProbeResults(\n",
    "        probe_name=\"\",\n",
    "        accuracy=metrics.accuracy,\n",
    "        perseverative_error_rate=metrics.perseverative_error_rate,\n",
    "        flexibility_index=metrics.flexibility_index,\n",
    "        switch_cost=metrics.switch_cost,\n",
    "        trials_to_recover=metrics.trials_to_recover\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_blend_probe(\n",
    "    model: CSTCNetwork,\n",
    "    visual_data: torch.Tensor,\n",
    "    visual_labels: torch.Tensor,\n",
    "    voice_labels: torch.Tensor,\n",
    "    rules: torch.Tensor,\n",
    "    blend_ratio: float,\n",
    "    device: torch.device,\n",
    "    batch_size: int = 32\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluate sensory integration by blending visual and conflicting voice inputs.\n",
    "    blend_ratio: 0.0 = pure visual, 1.0 = pure voice (conflicting)\n",
    "    Returns accuracy on visual labels (correct response despite interference).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Create blended labels: model must output visual labels despite voice interference\n",
    "    # We simulate this by interpolating the input transformation\n",
    "    # In practice, we modify the task to include interference in the input\n",
    "\n",
    "    n_sequences = visual_data.shape[0]\n",
    "    all_correct = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, n_sequences, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, n_sequences)\n",
    "\n",
    "            data = visual_data[start_idx:end_idx].to(device)\n",
    "            labels = visual_labels[start_idx:end_idx].to(device)\n",
    "            v_labels = voice_labels[start_idx:end_idx].to(device)\n",
    "\n",
    "            batch_size_actual, seq_len, _ = data.shape\n",
    "            hidden = model.init_hidden(batch_size_actual, device)\n",
    "\n",
    "            # Add interference noise proportional to blend_ratio\n",
    "            # This simulates conflicting sensory input\n",
    "            interference = torch.randn_like(data) * blend_ratio * 1.5\n",
    "            data_with_interference = data + interference\n",
    "\n",
    "            batch_preds = []\n",
    "            for t in range(seq_len):\n",
    "                logits, hidden = model(data_with_interference[:, t:t+1, :], hidden, return_hidden=True)\n",
    "                preds = logits.squeeze(1).argmax(dim=-1)\n",
    "                batch_preds.append(preds)\n",
    "\n",
    "            batch_preds = torch.stack(batch_preds, dim=1)\n",
    "            correct = (batch_preds == labels).float().mean(dim=1)\n",
    "            all_correct.extend(correct.cpu().tolist())\n",
    "\n",
    "    return np.mean(all_correct)\n",
    "\n",
    "\n",
    "def run_comprehensive_cognitive_evaluation(\n",
    "    model: CSTCNetwork,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    stage: str,\n",
    "    treatment: str,\n",
    "    timepoint_detail: str = \"\"\n",
    ") -> ComprehensiveCognitiveResults:\n",
    "    \"\"\"Run full cognitive battery and return comprehensive results.\"\"\"\n",
    "\n",
    "    # Get model state\n",
    "    sparsity = model.get_sparsity()\n",
    "    stress_level = model.stress_level\n",
    "    inhibition = model.inhibition_strength\n",
    "\n",
    "    # Standard task\n",
    "    std_results = evaluate_cognitive_probe(model, probe_loaders['standard'], device)\n",
    "\n",
    "    # Rotation probe (cognitive flexibility)\n",
    "    rot_results = evaluate_cognitive_probe(model, probe_loaders['rotation'], device)\n",
    "\n",
    "    # Scaling probe (visuospatial)\n",
    "    scale_results = evaluate_cognitive_probe(model, probe_loaders['scaling'], device)\n",
    "\n",
    "    # Fine discrimination (attention)\n",
    "    fine_results = evaluate_cognitive_probe(model, probe_loaders['fine_discrimination'], device)\n",
    "\n",
    "    # High noise (distraction resistance)\n",
    "    noise_results = evaluate_cognitive_probe(model, probe_loaders['high_noise'], device)\n",
    "\n",
    "    # High stress (internal stress resilience)\n",
    "    stress_results = evaluate_cognitive_probe(\n",
    "        model, probe_loaders['standard'], device,\n",
    "        apply_stress=CONFIG['cognitive_high_stress_level']\n",
    "    )\n",
    "\n",
    "    # Blend probes (sensory integration)\n",
    "    blend_25 = evaluate_blend_probe(\n",
    "        model,\n",
    "        probe_loaders['conflict_data'],\n",
    "        probe_loaders['conflict_visual_labels'],\n",
    "        probe_loaders['conflict_voice_labels'],\n",
    "        probe_loaders['conflict_rules'],\n",
    "        blend_ratio=0.25,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    blend_50 = evaluate_blend_probe(\n",
    "        model,\n",
    "        probe_loaders['conflict_data'],\n",
    "        probe_loaders['conflict_visual_labels'],\n",
    "        probe_loaders['conflict_voice_labels'],\n",
    "        probe_loaders['conflict_rules'],\n",
    "        blend_ratio=0.50,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    blend_75 = evaluate_blend_probe(\n",
    "        model,\n",
    "        probe_loaders['conflict_data'],\n",
    "        probe_loaders['conflict_visual_labels'],\n",
    "        probe_loaders['conflict_voice_labels'],\n",
    "        probe_loaders['conflict_rules'],\n",
    "        blend_ratio=0.75,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    return ComprehensiveCognitiveResults(\n",
    "        stage=stage,\n",
    "        treatment=treatment,\n",
    "        timepoint_detail=timepoint_detail,\n",
    "        sparsity=sparsity,\n",
    "        stress_level=stress_level,\n",
    "        inhibition_strength=inhibition,\n",
    "\n",
    "        standard_accuracy=std_results.accuracy,\n",
    "        standard_persev=std_results.perseverative_error_rate,\n",
    "        standard_flex=std_results.flexibility_index,\n",
    "        standard_switch_cost=std_results.switch_cost,\n",
    "        standard_recovery=std_results.trials_to_recover,\n",
    "\n",
    "        rotation_accuracy=rot_results.accuracy,\n",
    "        rotation_persev=rot_results.perseverative_error_rate,\n",
    "        rotation_flex=rot_results.flexibility_index,\n",
    "\n",
    "        scaling_accuracy=scale_results.accuracy,\n",
    "        scaling_persev=scale_results.perseverative_error_rate,\n",
    "        scaling_flex=scale_results.flexibility_index,\n",
    "\n",
    "        fine_disc_accuracy=fine_results.accuracy,\n",
    "        fine_disc_persev=fine_results.perseverative_error_rate,\n",
    "        fine_disc_flex=fine_results.flexibility_index,\n",
    "\n",
    "        high_noise_accuracy=noise_results.accuracy,\n",
    "        high_noise_persev=noise_results.perseverative_error_rate,\n",
    "        high_noise_flex=noise_results.flexibility_index,\n",
    "\n",
    "        high_stress_accuracy=stress_results.accuracy,\n",
    "        high_stress_persev=stress_results.perseverative_error_rate,\n",
    "        high_stress_flex=stress_results.flexibility_index,\n",
    "\n",
    "        blend_25_accuracy=blend_25,\n",
    "        blend_50_accuracy=blend_50,\n",
    "        blend_75_accuracy=blend_75\n",
    "    )\n",
    "\n",
    "\n",
    "def print_cognitive_results(results: ComprehensiveCognitiveResults, indent: int = 4):\n",
    "    \"\"\"Print cognitive results in formatted table.\"\"\"\n",
    "    prefix = \" \" * indent\n",
    "\n",
    "    print(f\"{prefix}Stage: {results.stage} | Treatment: {results.treatment} | {results.timepoint_detail}\")\n",
    "    print(f\"{prefix}Network State: Sparsity={results.sparsity*100:.1f}%, Stress={results.stress_level:.3f}, Inhibition={results.inhibition_strength:.2f}\")\n",
    "    print(f\"{prefix}\")\n",
    "    print(f\"{prefix}{'Probe':<20} {'Accuracy':>10} {'Persev':>10} {'Flex':>10}\")\n",
    "    print(f\"{prefix}{'-'*52}\")\n",
    "    print(f\"{prefix}{'Standard':<20} {results.standard_accuracy:>10.4f} {results.standard_persev:>10.4f} {results.standard_flex:>10.4f}\")\n",
    "    print(f\"{prefix}{'Rotation (45°)':<20} {results.rotation_accuracy:>10.4f} {results.rotation_persev:>10.4f} {results.rotation_flex:>10.4f}\")\n",
    "    print(f\"{prefix}{'Scaling (1.5x)':<20} {results.scaling_accuracy:>10.4f} {results.scaling_persev:>10.4f} {results.scaling_flex:>10.4f}\")\n",
    "    print(f\"{prefix}{'Fine Discrimination':<20} {results.fine_disc_accuracy:>10.4f} {results.fine_disc_persev:>10.4f} {results.fine_disc_flex:>10.4f}\")\n",
    "    print(f\"{prefix}{'High Noise':<20} {results.high_noise_accuracy:>10.4f} {results.high_noise_persev:>10.4f} {results.high_noise_flex:>10.4f}\")\n",
    "    print(f\"{prefix}{'High Stress':<20} {results.high_stress_accuracy:>10.4f} {results.high_stress_persev:>10.4f} {results.high_stress_flex:>10.4f}\")\n",
    "    print(f\"{prefix}\")\n",
    "    print(f\"{prefix}Sensory Integration (Blend Probes):\")\n",
    "    print(f\"{prefix}  25% Conflict: {results.blend_25_accuracy:.4f}\")\n",
    "    print(f\"{prefix}  50% Conflict: {results.blend_50_accuracy:.4f}\")\n",
    "    print(f\"{prefix}  75% Conflict: {results.blend_75_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def train_epoch(\n",
    "    model: CSTCNetwork,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "    pruning_manager: Optional[CSTCPruningManager] = None\n",
    ") -> float:\n",
    "    \"\"\"Train for one epoch, maintaining sparsity if pruning manager provided.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for data, labels, _ in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(data)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.view(-1, CONFIG['output_dim']),\n",
    "            labels.view(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        if pruning_manager is not None:\n",
    "            pruning_manager.apply_masks()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / n_batches\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: CSTCNetwork,\n",
    "    train_loader: DataLoader = None,\n",
    "    test_loader: DataLoader = None,\n",
    "    epochs: int = None,\n",
    "    lr: float = None,\n",
    "    pruning_manager: Optional[CSTCPruningManager] = None,\n",
    "    verbose: bool = True,\n",
    "    eval_interval: int = 10\n",
    ") -> Dict[str, List[float]]:\n",
    "    \"\"\"Full training loop with optional pruning maintenance.\"\"\"\n",
    "    if train_loader is None or test_loader is None:\n",
    "        train_loader, test_loader, _ = create_rule_switch_dataloaders()\n",
    "    if epochs is None:\n",
    "        epochs = CONFIG['baseline_epochs']\n",
    "    if lr is None:\n",
    "        lr = CONFIG['baseline_lr']\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {'loss': [], 'accuracy': [], 'perseveration': []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_epoch(model, train_loader, optimizer, criterion, device, pruning_manager)\n",
    "\n",
    "        history['loss'].append(loss)\n",
    "\n",
    "        if (epoch + 1) % eval_interval == 0 or epoch == epochs - 1:\n",
    "            metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "            history['accuracy'].append(metrics.accuracy)\n",
    "            history['perseveration'].append(metrics.perseverative_error_rate)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"    Epoch {epoch+1:3d}/{epochs}: Loss={loss:.4f}, \"\n",
    "                      f\"Acc={metrics.accuracy:.4f}, Persev={metrics.perseverative_error_rate:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_with_stress_schedule(\n",
    "    model: CSTCNetwork,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    initial_stress: float,\n",
    "    final_stress: float = 0.0,\n",
    "    pruning_manager: Optional[CSTCPruningManager] = None,\n",
    "    verbose: bool = False,\n",
    "    cognitive_eval_epochs: List[int] = None,\n",
    "    probe_loaders: Dict[str, Any] = None,\n",
    "    device: torch.device = None\n",
    ") -> Tuple[List[float], List[ComprehensiveCognitiveResults]]:\n",
    "    \"\"\"\n",
    "    SSRI-like: Prolonged training with gradually reducing internal noise.\n",
    "    Now includes mid-treatment cognitive evaluations.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = next(model.parameters()).device\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    mid_treatment_cognitive = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.reduce_stress_gradually(epoch, epochs, initial_stress, final_stress)\n",
    "\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for data, labels, _ in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(data)\n",
    "            loss = criterion(logits.view(-1, CONFIG['output_dim']), labels.view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            if pruning_manager:\n",
    "                pruning_manager.apply_masks()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        losses.append(epoch_loss / n_batches)\n",
    "\n",
    "        # Mid-treatment cognitive evaluation\n",
    "        if cognitive_eval_epochs and probe_loaders and (epoch + 1) in cognitive_eval_epochs:\n",
    "            cog_results = run_comprehensive_cognitive_evaluation(\n",
    "                model, probe_loaders, device,\n",
    "                stage=\"mid_treatment\",\n",
    "                treatment=\"ssri\",\n",
    "                timepoint_detail=f\"epoch_{epoch+1}/{epochs}\"\n",
    "            )\n",
    "            mid_treatment_cognitive.append(cog_results)\n",
    "\n",
    "        if verbose and (epoch + 1) % 30 == 0:\n",
    "            metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "            print(f\"      SSRI epoch {epoch+1}/{epochs} | stress: {model.stress_level:.3f} | \"\n",
    "                  f\"loss: {losses[-1]:.4f} | acc: {metrics.accuracy:.3f}\")\n",
    "\n",
    "    model.set_stress(final_stress)\n",
    "    return losses, mid_treatment_cognitive\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# THREE TREATMENT PROTOCOL FUNCTIONS (ENHANCED WITH COGNITIVE TRACKING)\n",
    "# =============================================================================\n",
    "\n",
    "def ketamine_treatment_ocd(\n",
    "    model: CSTCNetwork,\n",
    "    pruning_mgr: CSTCPruningManager,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    regrow_fraction: float = None,\n",
    "    consolidation_epochs: int = None,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[Dict[str, Any], List[ComprehensiveCognitiveResults]]:\n",
    "    \"\"\"Ketamine-like: Rapid structural synaptogenesis with cognitive tracking.\"\"\"\n",
    "    if regrow_fraction is None:\n",
    "        regrow_fraction = CONFIG['comparison_ketamine_regrow']\n",
    "    if consolidation_epochs is None:\n",
    "        consolidation_epochs = CONFIG['comparison_ketamine_epochs']\n",
    "\n",
    "    cognitive_trajectory = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"      [KETAMINE] regrow_fraction={regrow_fraction:.2f}, consolidation={consolidation_epochs} epochs\")\n",
    "\n",
    "    # Pre-treatment cognitive assessment\n",
    "    pre_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"pre_treatment\",\n",
    "        treatment=\"ketamine\",\n",
    "        timepoint_detail=\"before_regrowth\"\n",
    "    )\n",
    "    cognitive_trajectory.append(pre_cog)\n",
    "\n",
    "    # Regrowth (acute intervention)\n",
    "    regrow_stats = pruning_mgr.gradient_guided_regrow(\n",
    "        train_loader,\n",
    "        regrow_fraction=regrow_fraction\n",
    "    )\n",
    "    total_regrown = regrow_stats['connections_regrown']\n",
    "\n",
    "    # Post-regrowth, pre-consolidation\n",
    "    post_regrow_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"during_treatment\",\n",
    "        treatment=\"ketamine\",\n",
    "        timepoint_detail=\"post_regrowth_pre_consolidation\"\n",
    "    )\n",
    "    cognitive_trajectory.append(post_regrow_cog)\n",
    "\n",
    "    # Consolidation training\n",
    "    train(\n",
    "        model, train_loader, test_loader,\n",
    "        epochs=consolidation_epochs,\n",
    "        lr=CONFIG['finetune_lr'],\n",
    "        pruning_manager=pruning_mgr,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Post-treatment cognitive assessment\n",
    "    post_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"post_treatment\",\n",
    "        treatment=\"ketamine\",\n",
    "        timepoint_detail=\"after_consolidation\"\n",
    "    )\n",
    "    cognitive_trajectory.append(post_cog)\n",
    "\n",
    "    final_sparsity = pruning_mgr.get_sparsity()\n",
    "\n",
    "    treatment_info = {\n",
    "        'treatment': 'ketamine',\n",
    "        'mechanism': 'structural',\n",
    "        'regrown': total_regrown,\n",
    "        'regrow_fraction': regrow_fraction,\n",
    "        'consolidation_epochs': consolidation_epochs,\n",
    "        'final_sparsity': final_sparsity\n",
    "    }\n",
    "\n",
    "    return treatment_info, cognitive_trajectory\n",
    "\n",
    "\n",
    "def ssri_treatment_ocd(\n",
    "    model: CSTCNetwork,\n",
    "    pruning_mgr: CSTCPruningManager,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    epochs: int = None,\n",
    "    lr: float = None,\n",
    "    initial_stress: float = None,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[Dict[str, Any], List[ComprehensiveCognitiveResults]]:\n",
    "    \"\"\"SSRI-like: Gradual functional stabilization with cognitive tracking.\"\"\"\n",
    "    if epochs is None:\n",
    "        epochs = CONFIG['comparison_ssri_epochs']\n",
    "    if lr is None:\n",
    "        lr = CONFIG['comparison_ssri_lr']\n",
    "    if initial_stress is None:\n",
    "        initial_stress = CONFIG['comparison_ssri_initial_stress']\n",
    "\n",
    "    cognitive_trajectory = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"      [SSRI] epochs={epochs}, lr={lr:.0e}, initial_stress={initial_stress:.2f}\")\n",
    "\n",
    "    initial_sparsity = pruning_mgr.get_sparsity()\n",
    "\n",
    "    # Pre-treatment cognitive assessment\n",
    "    pre_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"pre_treatment\",\n",
    "        treatment=\"ssri\",\n",
    "        timepoint_detail=\"before_training\"\n",
    "    )\n",
    "    cognitive_trajectory.append(pre_cog)\n",
    "\n",
    "    # Calculate mid-treatment evaluation epochs\n",
    "    eval_fractions = CONFIG['ssri_mid_eval_points']\n",
    "    cognitive_eval_epochs = [int(f * epochs) for f in eval_fractions]\n",
    "\n",
    "    # Training with stress schedule and mid-treatment evals\n",
    "    losses, mid_treatment_cog = train_with_stress_schedule(\n",
    "        model, train_loader, test_loader,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        initial_stress=initial_stress,\n",
    "        final_stress=0.0,\n",
    "        pruning_manager=pruning_mgr,\n",
    "        verbose=False,\n",
    "        cognitive_eval_epochs=cognitive_eval_epochs,\n",
    "        probe_loaders=probe_loaders,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    cognitive_trajectory.extend(mid_treatment_cog)\n",
    "\n",
    "    # Post-treatment cognitive assessment\n",
    "    post_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"post_treatment\",\n",
    "        treatment=\"ssri\",\n",
    "        timepoint_detail=\"after_full_course\"\n",
    "    )\n",
    "    cognitive_trajectory.append(post_cog)\n",
    "\n",
    "    final_sparsity = pruning_mgr.get_sparsity()\n",
    "\n",
    "    treatment_info = {\n",
    "        'treatment': 'ssri',\n",
    "        'mechanism': 'functional',\n",
    "        'epochs': epochs,\n",
    "        'lr': lr,\n",
    "        'initial_stress': initial_stress,\n",
    "        'final_stress': model.stress_level,\n",
    "        'initial_sparsity': initial_sparsity,\n",
    "        'final_sparsity': final_sparsity\n",
    "    }\n",
    "\n",
    "    return treatment_info, cognitive_trajectory\n",
    "\n",
    "\n",
    "def neurosteroid_treatment_ocd(\n",
    "    model: CSTCNetwork,\n",
    "    pruning_mgr: CSTCPruningManager,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    strength: float = None,\n",
    "    use_tanh: bool = None,\n",
    "    consolidation_epochs: int = None,\n",
    "    verbose: bool = True\n",
    ") -> Tuple[Dict[str, Any], List[ComprehensiveCognitiveResults]]:\n",
    "    \"\"\"Neurosteroid-like: Rapid tonic inhibition with cognitive tracking.\"\"\"\n",
    "    if strength is None:\n",
    "        strength = CONFIG['comparison_neurosteroid_strength']\n",
    "    if use_tanh is None:\n",
    "        use_tanh = CONFIG['comparison_neurosteroid_use_tanh']\n",
    "    if consolidation_epochs is None:\n",
    "        consolidation_epochs = CONFIG['comparison_neurosteroid_epochs']\n",
    "\n",
    "    cognitive_trajectory = []\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"      [NEUROSTEROID] strength={strength:.2f}, use_tanh={use_tanh}, consolidation={consolidation_epochs} epochs\")\n",
    "\n",
    "    initial_sparsity = pruning_mgr.get_sparsity()\n",
    "\n",
    "    # Pre-treatment cognitive assessment (off medication)\n",
    "    pre_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"pre_treatment\",\n",
    "        treatment=\"neurosteroid\",\n",
    "        timepoint_detail=\"before_medication\"\n",
    "    )\n",
    "    cognitive_trajectory.append(pre_cog)\n",
    "\n",
    "    # Apply medication\n",
    "    model.set_inhibition(strength, use_tanh)\n",
    "\n",
    "    # Immediate post-medication, pre-consolidation\n",
    "    immediate_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"during_treatment\",\n",
    "        treatment=\"neurosteroid\",\n",
    "        timepoint_detail=\"immediate_medication_effect\"\n",
    "    )\n",
    "    cognitive_trajectory.append(immediate_cog)\n",
    "\n",
    "    # Consolidation training\n",
    "    train(\n",
    "        model, train_loader, test_loader,\n",
    "        epochs=consolidation_epochs,\n",
    "        lr=CONFIG['finetune_lr'],\n",
    "        pruning_manager=pruning_mgr,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Post-consolidation (on medication)\n",
    "    post_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"post_treatment\",\n",
    "        treatment=\"neurosteroid\",\n",
    "        timepoint_detail=\"after_consolidation_on_med\"\n",
    "    )\n",
    "    cognitive_trajectory.append(post_cog)\n",
    "\n",
    "    # Off-medication assessment\n",
    "    model.set_inhibition(1.0, False)\n",
    "    off_med_cog = run_comprehensive_cognitive_evaluation(\n",
    "        model, probe_loaders, device,\n",
    "        stage=\"off_medication\",\n",
    "        treatment=\"neurosteroid\",\n",
    "        timepoint_detail=\"medication_discontinued\"\n",
    "    )\n",
    "    cognitive_trajectory.append(off_med_cog)\n",
    "\n",
    "    # Restore medication for subsequent tests\n",
    "    model.set_inhibition(strength, use_tanh)\n",
    "\n",
    "    final_sparsity = pruning_mgr.get_sparsity()\n",
    "\n",
    "    treatment_info = {\n",
    "        'treatment': 'neurosteroid',\n",
    "        'mechanism': 'functional_medication_dependent',\n",
    "        'strength': strength,\n",
    "        'use_tanh': use_tanh,\n",
    "        'consolidation_epochs': consolidation_epochs,\n",
    "        'initial_sparsity': initial_sparsity,\n",
    "        'final_sparsity': final_sparsity\n",
    "    }\n",
    "\n",
    "    return treatment_info, cognitive_trajectory\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ISO-DOSE PARAMETER SWEEP FUNCTIONS (PRESERVED WITH COGNITIVE ADDITIONS)\n",
    "# =============================================================================\n",
    "\n",
    "def run_ketamine_sweep(\n",
    "    base_state: Dict[str, torch.Tensor],\n",
    "    base_masks: Dict[str, torch.Tensor],\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    regrow_fractions: List[float] = None\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Sweep ketamine regrow_fraction and measure dose + outcomes + cognition.\"\"\"\n",
    "    if regrow_fractions is None:\n",
    "        regrow_fractions = CONFIG['ketamine_regrow_sweep']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for regrow_frac in regrow_fractions:\n",
    "        model = CSTCNetwork().to(device)\n",
    "        model.load_state_dict(copy.deepcopy(base_state))\n",
    "        mgr = CSTCPruningManager(model)\n",
    "        mgr.masks = copy.deepcopy(base_masks)\n",
    "        mgr.apply_masks()\n",
    "\n",
    "        pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n",
    "\n",
    "        # Run treatment with cognitive tracking\n",
    "        treatment_info, cog_trajectory = ketamine_treatment_ocd(\n",
    "            model, mgr, train_loader, test_loader, probe_loaders, device,\n",
    "            regrow_fraction=regrow_frac,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        dose_metrics = compute_all_dose_metrics(pre_state, model)\n",
    "        acute_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "        # Relapse simulation with cognitive assessment\n",
    "        pre_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "            model, probe_loaders, device,\n",
    "            stage=\"pre_relapse\",\n",
    "            treatment=\"ketamine\",\n",
    "            timepoint_detail=f\"regrow_{regrow_frac:.2f}\"\n",
    "        )\n",
    "\n",
    "        pre_relapse_persev = acute_metrics.perseverative_error_rate\n",
    "        mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n",
    "\n",
    "        post_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "            model, probe_loaders, device,\n",
    "            stage=\"post_relapse\",\n",
    "            treatment=\"ketamine\",\n",
    "            timepoint_detail=f\"regrow_{regrow_frac:.2f}\"\n",
    "        )\n",
    "\n",
    "        relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "        results.append({\n",
    "            'treatment': 'ketamine',\n",
    "            'param_name': 'regrow_fraction',\n",
    "            'param_value': regrow_frac,\n",
    "            'dose': dose_metrics,\n",
    "            'acute_persev': acute_metrics.perseverative_error_rate,\n",
    "            'acute_flex': acute_metrics.flexibility_index,\n",
    "            'acute_accuracy': acute_metrics.accuracy,\n",
    "            'relapse_persev': relapse_metrics.perseverative_error_rate,\n",
    "            'relapse_delta': relapse_metrics.perseverative_error_rate - pre_relapse_persev,\n",
    "            'treatment_info': treatment_info,\n",
    "            'cognitive_trajectory': cog_trajectory,\n",
    "            'pre_relapse_cognitive': pre_relapse_cog,\n",
    "            'post_relapse_cognitive': post_relapse_cog\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_ssri_sweep(\n",
    "    base_state: Dict[str, torch.Tensor],\n",
    "    base_masks: Dict[str, torch.Tensor],\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    epochs_list: List[int] = None,\n",
    "    lr_list: List[float] = None\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Sweep SSRI epochs and LR, measure dose + outcomes + cognition.\"\"\"\n",
    "    if epochs_list is None:\n",
    "        epochs_list = CONFIG['ssri_epochs_sweep']\n",
    "    if lr_list is None:\n",
    "        lr_list = [CONFIG['comparison_ssri_lr']]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for epochs in epochs_list:\n",
    "        for lr in lr_list:\n",
    "            model = CSTCNetwork().to(device)\n",
    "            model.load_state_dict(copy.deepcopy(base_state))\n",
    "            mgr = CSTCPruningManager(model)\n",
    "            mgr.masks = copy.deepcopy(base_masks)\n",
    "            mgr.apply_masks()\n",
    "\n",
    "            pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n",
    "\n",
    "            treatment_info, cog_trajectory = ssri_treatment_ocd(\n",
    "                model, mgr, train_loader, test_loader, probe_loaders, device,\n",
    "                epochs=epochs,\n",
    "                lr=lr,\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            dose_metrics = compute_all_dose_metrics(pre_state, model)\n",
    "            acute_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "            # Relapse simulation\n",
    "            pre_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "                model, probe_loaders, device,\n",
    "                stage=\"pre_relapse\",\n",
    "                treatment=\"ssri\",\n",
    "                timepoint_detail=f\"epochs_{epochs}\"\n",
    "            )\n",
    "\n",
    "            pre_relapse_persev = acute_metrics.perseverative_error_rate\n",
    "            mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n",
    "\n",
    "            post_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "                model, probe_loaders, device,\n",
    "                stage=\"post_relapse\",\n",
    "                treatment=\"ssri\",\n",
    "                timepoint_detail=f\"epochs_{epochs}\"\n",
    "            )\n",
    "\n",
    "            relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "            results.append({\n",
    "                'treatment': 'ssri',\n",
    "                'param_name': 'epochs',\n",
    "                'param_value': epochs,\n",
    "                'lr': lr,\n",
    "                'dose': dose_metrics,\n",
    "                'acute_persev': acute_metrics.perseverative_error_rate,\n",
    "                'acute_flex': acute_metrics.flexibility_index,\n",
    "                'acute_accuracy': acute_metrics.accuracy,\n",
    "                'relapse_persev': relapse_metrics.perseverative_error_rate,\n",
    "                'relapse_delta': relapse_metrics.perseverative_error_rate - pre_relapse_persev,\n",
    "                'treatment_info': treatment_info,\n",
    "                'cognitive_trajectory': cog_trajectory,\n",
    "                'pre_relapse_cognitive': pre_relapse_cog,\n",
    "                'post_relapse_cognitive': post_relapse_cog\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_neurosteroid_sweep(\n",
    "    base_state: Dict[str, torch.Tensor],\n",
    "    base_masks: Dict[str, torch.Tensor],\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    probe_loaders: Dict[str, Any],\n",
    "    device: torch.device,\n",
    "    strength_list: List[float] = None\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Sweep neurosteroid strength, measure dose + outcomes + cognition.\"\"\"\n",
    "    if strength_list is None:\n",
    "        strength_list = CONFIG['neurosteroid_strength_sweep']\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for strength in strength_list:\n",
    "        model = CSTCNetwork().to(device)\n",
    "        model.load_state_dict(copy.deepcopy(base_state))\n",
    "        mgr = CSTCPruningManager(model)\n",
    "        mgr.masks = copy.deepcopy(base_masks)\n",
    "        mgr.apply_masks()\n",
    "\n",
    "        pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n",
    "\n",
    "        treatment_info, cog_trajectory = neurosteroid_treatment_ocd(\n",
    "            model, mgr, train_loader, test_loader, probe_loaders, device,\n",
    "            strength=strength,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        dose_metrics = compute_all_dose_metrics(pre_state, model)\n",
    "        acute_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "        # Off-medication test (already in trajectory, but get metrics)\n",
    "        model.set_inhibition(1.0, False)\n",
    "        off_med_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "        model.set_inhibition(strength, CONFIG['comparison_neurosteroid_use_tanh'])\n",
    "\n",
    "        # Relapse simulation\n",
    "        pre_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "            model, probe_loaders, device,\n",
    "            stage=\"pre_relapse\",\n",
    "            treatment=\"neurosteroid\",\n",
    "            timepoint_detail=f\"strength_{strength:.2f}\"\n",
    "        )\n",
    "\n",
    "        pre_relapse_persev = acute_metrics.perseverative_error_rate\n",
    "        mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n",
    "\n",
    "        post_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "            model, probe_loaders, device,\n",
    "            stage=\"post_relapse\",\n",
    "            treatment=\"neurosteroid\",\n",
    "            timepoint_detail=f\"strength_{strength:.2f}\"\n",
    "        )\n",
    "\n",
    "        relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "        results.append({\n",
    "            'treatment': 'neurosteroid',\n",
    "            'param_name': 'strength',\n",
    "            'param_value': strength,\n",
    "            'dose': dose_metrics,\n",
    "            'acute_persev': acute_metrics.perseverative_error_rate,\n",
    "            'acute_flex': acute_metrics.flexibility_index,\n",
    "            'acute_accuracy': acute_metrics.accuracy,\n",
    "            'off_med_persev': off_med_metrics.perseverative_error_rate,\n",
    "            'off_med_reversal': off_med_metrics.perseverative_error_rate - acute_metrics.perseverative_error_rate,\n",
    "            'relapse_persev': relapse_metrics.perseverative_error_rate,\n",
    "            'relapse_delta': relapse_metrics.perseverative_error_rate - pre_relapse_persev,\n",
    "            'treatment_info': treatment_info,\n",
    "            'cognitive_trajectory': cog_trajectory,\n",
    "            'pre_relapse_cognitive': pre_relapse_cog,\n",
    "            'post_relapse_cognitive': post_relapse_cog\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def find_iso_dose_params(\n",
    "    sweep_results: List[Dict[str, Any]],\n",
    "    target_dose: float,\n",
    "    tolerance: float = None\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Find parameter configuration closest to target dose.\"\"\"\n",
    "    if tolerance is None:\n",
    "        tolerance = CONFIG['iso_dose_tolerance']\n",
    "\n",
    "    best_match = None\n",
    "    best_diff = float('inf')\n",
    "\n",
    "    for result in sweep_results:\n",
    "        dose = result['dose'].l1_norm\n",
    "        diff = abs(dose - target_dose)\n",
    "        if diff < best_diff:\n",
    "            best_diff = diff\n",
    "            best_match = result\n",
    "\n",
    "    if best_match and best_diff <= tolerance:\n",
    "        return best_match\n",
    "    return best_match\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DETAILED COGNITIVE RESULTS PRINTING\n",
    "# =============================================================================\n",
    "\n",
    "def print_cognitive_trajectory(\n",
    "    trajectory: List[ComprehensiveCognitiveResults],\n",
    "    treatment_name: str,\n",
    "    indent: int = 4\n",
    "):\n",
    "    \"\"\"Print full cognitive trajectory for a treatment.\"\"\"\n",
    "    prefix = \" \" * indent\n",
    "\n",
    "    print(f\"\\n{prefix}{'='*70}\")\n",
    "    print(f\"{prefix}COGNITIVE TRAJECTORY: {treatment_name.upper()}\")\n",
    "    print(f\"{prefix}{'='*70}\")\n",
    "\n",
    "    for i, results in enumerate(trajectory):\n",
    "        print(f\"\\n{prefix}[{i+1}] {results.stage.upper()} - {results.timepoint_detail}\")\n",
    "        print(f\"{prefix}{'-'*60}\")\n",
    "        print_cognitive_results(results, indent=indent+2)\n",
    "\n",
    "\n",
    "def print_cognitive_comparison_table(\n",
    "    all_results: Dict[str, List[ComprehensiveCognitiveResults]],\n",
    "    stage_filter: str = None,\n",
    "    indent: int = 4\n",
    "):\n",
    "    \"\"\"Print comparative cognitive table across treatments.\"\"\"\n",
    "    prefix = \" \" * indent\n",
    "\n",
    "    # Collect all stages\n",
    "    stages = set()\n",
    "    for treatment_results in all_results.values():\n",
    "        for r in treatment_results:\n",
    "            stages.add(r.stage)\n",
    "\n",
    "    if stage_filter:\n",
    "        stages = {stage_filter}\n",
    "\n",
    "    for stage in sorted(stages):\n",
    "        print(f\"\\n{prefix}{'='*80}\")\n",
    "        print(f\"{prefix}COGNITIVE COMPARISON: {stage.upper()}\")\n",
    "        print(f\"{prefix}{'='*80}\")\n",
    "\n",
    "        # Header\n",
    "        print(f\"\\n{prefix}{'Probe':<20}\", end=\"\")\n",
    "        for treatment in all_results.keys():\n",
    "            print(f\"{treatment:>18}\", end=\"\")\n",
    "        print()\n",
    "        print(f\"{prefix}{'-'*80}\")\n",
    "\n",
    "        # Get results for this stage\n",
    "        stage_results = {}\n",
    "        for treatment, results_list in all_results.items():\n",
    "            for r in results_list:\n",
    "                if r.stage == stage:\n",
    "                    stage_results[treatment] = r\n",
    "                    break\n",
    "\n",
    "        # Print each probe\n",
    "        probes = [\n",
    "            ('Standard Acc', 'standard_accuracy'),\n",
    "            ('Standard Persev', 'standard_persev'),\n",
    "            ('Rotation Acc', 'rotation_accuracy'),\n",
    "            ('Rotation Persev', 'rotation_persev'),\n",
    "            ('Scaling Acc', 'scaling_accuracy'),\n",
    "            ('Fine Disc Acc', 'fine_disc_accuracy'),\n",
    "            ('High Noise Acc', 'high_noise_accuracy'),\n",
    "            ('High Stress Acc', 'high_stress_accuracy'),\n",
    "            ('Blend 25%', 'blend_25_accuracy'),\n",
    "            ('Blend 50%', 'blend_50_accuracy'),\n",
    "            ('Blend 75%', 'blend_75_accuracy'),\n",
    "        ]\n",
    "\n",
    "        for probe_name, attr_name in probes:\n",
    "            print(f\"{prefix}{probe_name:<20}\", end=\"\")\n",
    "            for treatment in all_results.keys():\n",
    "                if treatment in stage_results:\n",
    "                    val = getattr(stage_results[treatment], attr_name, None)\n",
    "                    if val is not None:\n",
    "                        print(f\"{val:>18.4f}\", end=\"\")\n",
    "                    else:\n",
    "                        print(f\"{'N/A':>18}\", end=\"\")\n",
    "                else:\n",
    "                    print(f\"{'N/A':>18}\", end=\"\")\n",
    "            print()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ISO-DOSE COMPARISON EXPERIMENT (ENHANCED)\n",
    "# =============================================================================\n",
    "\n",
    "def run_iso_dose_comparison_experiment(\n",
    "    device: torch.device,\n",
    "    seed: int = None,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run iso-dose comparison across all three treatment mechanisms\n",
    "    with comprehensive cognitive testing at all stages.\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        seed = CONFIG['seed']\n",
    "    set_seed(seed)\n",
    "\n",
    "    print_section_header(\"ISO-DOSE FAIR COMPARISON EXPERIMENT\", char=\"█\")\n",
    "    print_section_header(\"WITH COGNITIVE TESTING THROUGHOUT ILLNESS COURSE\", char=\"█\")\n",
    "    print(f\"\\n  Seed: {seed}\")\n",
    "    print(f\"  Device: {device}\")\n",
    "    print(f\"  Dose metric: L1 weight change norm (normalized per parameter)\")\n",
    "\n",
    "    train_loader, test_loader, _ = create_rule_switch_dataloaders()\n",
    "    probe_loaders = create_cognitive_probe_loaders()\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 1: Create shared pruned baseline with cognitive assessments\n",
    "    # =========================================================================\n",
    "    print_subsection_header(\"PHASE 1: Creating Shared Pruned Baseline\")\n",
    "\n",
    "    base_model = CSTCNetwork().to(device)\n",
    "\n",
    "    # Healthy baseline cognitive assessment (before any training)\n",
    "    print(\"  Evaluating pre-training (random initialization) cognitive state...\")\n",
    "\n",
    "    print(\"  Training healthy baseline model...\")\n",
    "    train(base_model, train_loader, test_loader, verbose=False)\n",
    "\n",
    "    # Healthy trained baseline cognitive assessment\n",
    "    print(\"  Evaluating healthy trained baseline cognitive state...\")\n",
    "    healthy_cognitive = run_comprehensive_cognitive_evaluation(\n",
    "        base_model, probe_loaders, device,\n",
    "        stage=\"healthy_baseline\",\n",
    "        treatment=\"none\",\n",
    "        timepoint_detail=\"fully_trained_healthy\"\n",
    "    )\n",
    "\n",
    "    base_mgr = CSTCPruningManager(base_model)\n",
    "    prune_stats = base_mgr.prune_by_magnitude(sparsity=CONFIG['ocd_prune_sparsity'])\n",
    "\n",
    "    print(f\"  Applied developmental over-pruning: {CONFIG['ocd_prune_sparsity']*100:.0f}%\")\n",
    "    print(f\"  Achieved sparsity: {prune_stats['achieved_sparsity']*100:.1f}%\")\n",
    "\n",
    "    # Post-pruning (OCD onset) cognitive assessment\n",
    "    print(\"  Evaluating post-pruning (OCD onset) cognitive state...\")\n",
    "    ocd_onset_cognitive = run_comprehensive_cognitive_evaluation(\n",
    "        base_model, probe_loaders, device,\n",
    "        stage=\"ocd_onset\",\n",
    "        treatment=\"untreated\",\n",
    "        timepoint_detail=\"immediately_post_pruning\"\n",
    "    )\n",
    "\n",
    "    base_state = copy.deepcopy(base_model.state_dict())\n",
    "    base_masks = copy.deepcopy(base_mgr.masks)\n",
    "\n",
    "    untreated_metrics = compute_ocd_metrics(base_model, test_loader, device)\n",
    "    print(f\"\\n  UNTREATED OCD BASELINE:\")\n",
    "    print(f\"    Perseverative Errors: {untreated_metrics.perseverative_error_rate:.4f}\")\n",
    "    print(f\"    Flexibility Index:    {untreated_metrics.flexibility_index:.4f}\")\n",
    "    print(f\"    Accuracy:             {untreated_metrics.accuracy:.4f}\")\n",
    "\n",
    "    # Print baseline cognitive comparisons\n",
    "    print_subsection_header(\"COGNITIVE STATE: HEALTHY vs OCD ONSET\")\n",
    "    print_cognitive_comparison_table(\n",
    "        {'Healthy': [healthy_cognitive], 'OCD_Onset': [ocd_onset_cognitive]},\n",
    "        indent=4\n",
    "    )\n",
    "\n",
    "    results = {\n",
    "        'untreated': {\n",
    "            'persev': untreated_metrics.perseverative_error_rate,\n",
    "            'flex': untreated_metrics.flexibility_index,\n",
    "            'accuracy': untreated_metrics.accuracy,\n",
    "            'sparsity': untreated_metrics.sparsity\n",
    "        },\n",
    "        'cognitive_baselines': {\n",
    "            'healthy': healthy_cognitive,\n",
    "            'ocd_onset': ocd_onset_cognitive\n",
    "        },\n",
    "        'sweeps': {},\n",
    "        'iso_dose_comparisons': {},\n",
    "        'all_cognitive_trajectories': {}\n",
    "    }\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 2: Parameter Sweeps with Cognitive Tracking\n",
    "    # =========================================================================\n",
    "    print_subsection_header(\"PHASE 2: Parameter Sweeps (Measuring Dose-Response + Cognition)\")\n",
    "\n",
    "    print(\"\\n  [KETAMINE] Sweeping regrow_fraction...\")\n",
    "    ketamine_results = run_ketamine_sweep(\n",
    "        base_state, base_masks, train_loader, test_loader, probe_loaders, device\n",
    "    )\n",
    "    results['sweeps']['ketamine'] = ketamine_results\n",
    "    print(f\"    Completed {len(ketamine_results)} configurations\")\n",
    "\n",
    "    print(\"\\n  [SSRI] Sweeping epochs...\")\n",
    "    ssri_results = run_ssri_sweep(\n",
    "        base_state, base_masks, train_loader, test_loader, probe_loaders, device\n",
    "    )\n",
    "    results['sweeps']['ssri'] = ssri_results\n",
    "    print(f\"    Completed {len(ssri_results)} configurations\")\n",
    "\n",
    "    print(\"\\n  [NEUROSTEROID] Sweeping strength...\")\n",
    "    neurosteroid_results = run_neurosteroid_sweep(\n",
    "        base_state, base_masks, train_loader, test_loader, probe_loaders, device\n",
    "    )\n",
    "    results['sweeps']['neurosteroid'] = neurosteroid_results\n",
    "    print(f\"    Completed {len(neurosteroid_results)} configurations\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 3: Dose-Response Analysis\n",
    "    # =========================================================================\n",
    "    print_subsection_header(\"PHASE 3: Dose-Response Curves\")\n",
    "\n",
    "    print(\"\\n  KETAMINE DOSE-RESPONSE:\")\n",
    "    print(f\"  {'regrow_frac':>12} {'L1 Dose':>12} {'Turnover':>12} {'Acute Prsv':>12} {'Relapse Δ':>12}\")\n",
    "    print(\"  \" + \"-\" * 64)\n",
    "    for r in ketamine_results:\n",
    "        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {r['dose'].synaptic_turnover:>12.4f} \"\n",
    "              f\"{r['acute_persev']:>12.4f} {r['relapse_delta']:>+12.4f}\")\n",
    "\n",
    "    print(\"\\n  SSRI DOSE-RESPONSE:\")\n",
    "    print(f\"  {'epochs':>12} {'L1 Dose':>12} {'Turnover':>12} {'Acute Prsv':>12} {'Relapse Δ':>12}\")\n",
    "    print(\"  \" + \"-\" * 64)\n",
    "    for r in ssri_results:\n",
    "        print(f\"  {r['param_value']:>12} {r['dose'].l1_norm:>12.6f} {r['dose'].synaptic_turnover:>12.4f} \"\n",
    "              f\"{r['acute_persev']:>12.4f} {r['relapse_delta']:>+12.4f}\")\n",
    "\n",
    "    print(\"\\n  NEUROSTEROID DOSE-RESPONSE:\")\n",
    "    print(f\"  {'strength':>12} {'L1 Dose':>12} {'Turnover':>12} {'Acute Prsv':>12} {'Off-med Δ':>12} {'Relapse Δ':>12}\")\n",
    "    print(\"  \" + \"-\" * 76)\n",
    "    for r in neurosteroid_results:\n",
    "        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {r['dose'].synaptic_turnover:>12.4f} \"\n",
    "              f\"{r['acute_persev']:>12.4f} {r['off_med_reversal']:>+12.4f} {r['relapse_delta']:>+12.4f}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 4: Iso-Dose Matching\n",
    "    # =========================================================================\n",
    "    print_subsection_header(\"PHASE 4: Iso-Dose Matched Comparisons\")\n",
    "\n",
    "    all_doses = []\n",
    "    for r in ketamine_results:\n",
    "        all_doses.append(r['dose'].l1_norm)\n",
    "    for r in ssri_results:\n",
    "        all_doses.append(r['dose'].l1_norm)\n",
    "    for r in neurosteroid_results:\n",
    "        all_doses.append(r['dose'].l1_norm)\n",
    "\n",
    "    dose_range = (min(all_doses), max(all_doses))\n",
    "    print(f\"\\n  Observed dose range: {dose_range[0]:.6f} - {dose_range[1]:.6f}\")\n",
    "\n",
    "    target_doses = CONFIG['iso_dose_target_doses']\n",
    "    valid_targets = [d for d in target_doses if dose_range[0] <= d <= dose_range[1]]\n",
    "\n",
    "    if not valid_targets:\n",
    "        dose_percentiles = [25, 50, 75]\n",
    "        valid_targets = [np.percentile(all_doses, p) for p in dose_percentiles]\n",
    "        print(f\"  Using dose percentiles: {[f'{d:.6f}' for d in valid_targets]}\")\n",
    "    else:\n",
    "        print(f\"  Target doses: {valid_targets}\")\n",
    "\n",
    "    for target_dose in valid_targets:\n",
    "        print(f\"\\n  ISO-DOSE TARGET: {target_dose:.6f}\")\n",
    "        print(\"  \" + \"=\" * 70)\n",
    "\n",
    "        ket_match = find_iso_dose_params(ketamine_results, target_dose)\n",
    "        ssri_match = find_iso_dose_params(ssri_results, target_dose)\n",
    "        neuro_match = find_iso_dose_params(neurosteroid_results, target_dose)\n",
    "\n",
    "        iso_comparison = {\n",
    "            'target_dose': target_dose,\n",
    "            'ketamine': ket_match,\n",
    "            'ssri': ssri_match,\n",
    "            'neurosteroid': neuro_match\n",
    "        }\n",
    "        results['iso_dose_comparisons'][target_dose] = iso_comparison\n",
    "\n",
    "        print(f\"\\n  {'Treatment':<15} {'Param':<15} {'Actual Dose':>12} {'Acute Prsv':>12} {'Relapse Δ':>12} {'Efficiency':>12}\")\n",
    "        print(\"  \" + \"-\" * 80)\n",
    "\n",
    "        for name, match in [('Ketamine', ket_match), ('SSRI', ssri_match), ('Neurosteroid', neuro_match)]:\n",
    "            if match:\n",
    "                param_str = f\"{match['param_name']}={match['param_value']}\"\n",
    "                actual_dose = match['dose'].l1_norm\n",
    "                acute_p = match['acute_persev']\n",
    "                relapse_d = match['relapse_delta']\n",
    "\n",
    "                persev_reduction = untreated_metrics.perseverative_error_rate - acute_p\n",
    "                efficiency = persev_reduction / (actual_dose + 1e-8)\n",
    "\n",
    "                print(f\"  {name:<15} {param_str:<15} {actual_dose:>12.6f} {acute_p:>12.4f} {relapse_d:>+12.4f} {efficiency:>12.2f}\")\n",
    "            else:\n",
    "                print(f\"  {name:<15} {'N/A':<15} {'N/A':>12} {'N/A':>12} {'N/A':>12} {'N/A':>12}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 5: Efficiency Analysis\n",
    "    # =========================================================================\n",
    "    print_subsection_header(\"PHASE 5: Treatment Efficiency Analysis\")\n",
    "\n",
    "    print(\"\\n  EFFICIENCY = (Perseveration Reduction) / (L1 Dose)\")\n",
    "    print(\"  Higher efficiency = better outcome per unit of network change\")\n",
    "\n",
    "    print(\"\\n  KETAMINE EFFICIENCY:\")\n",
    "    print(f\"  {'regrow_frac':>12} {'Dose':>12} {'Prsv Reduc':>12} {'Efficiency':>12}\")\n",
    "    print(\"  \" + \"-\" * 52)\n",
    "    for r in ketamine_results:\n",
    "        reduction = untreated_metrics.perseverative_error_rate - r['acute_persev']\n",
    "        efficiency = reduction / (r['dose'].l1_norm + 1e-8)\n",
    "        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {reduction:>12.4f} {efficiency:>12.2f}\")\n",
    "\n",
    "    print(\"\\n  SSRI EFFICIENCY:\")\n",
    "    print(f\"  {'epochs':>12} {'Dose':>12} {'Prsv Reduc':>12} {'Efficiency':>12}\")\n",
    "    print(\"  \" + \"-\" * 52)\n",
    "    for r in ssri_results:\n",
    "        reduction = untreated_metrics.perseverative_error_rate - r['acute_persev']\n",
    "        efficiency = reduction / (r['dose'].l1_norm + 1e-8)\n",
    "        print(f\"  {r['param_value']:>12} {r['dose'].l1_norm:>12.6f} {reduction:>12.4f} {efficiency:>12.2f}\")\n",
    "\n",
    "    print(\"\\n  NEUROSTEROID EFFICIENCY:\")\n",
    "    print(f\"  {'strength':>12} {'Dose':>12} {'Prsv Reduc':>12} {'Efficiency':>12}\")\n",
    "    print(\"  \" + \"-\" * 52)\n",
    "    for r in neurosteroid_results:\n",
    "        reduction = untreated_metrics.perseverative_error_rate - r['acute_persev']\n",
    "        efficiency = reduction / (r['dose'].l1_norm + 1e-8)\n",
    "        print(f\"  {r['param_value']:>12.2f} {r['dose'].l1_norm:>12.6f} {reduction:>12.4f} {efficiency:>12.2f}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 6: Summary Statistics\n",
    "    # =========================================================================\n",
    "    print_subsection_header(\"PHASE 6: Summary Statistics\")\n",
    "\n",
    "    def compute_sweep_stats(sweep_results):\n",
    "        doses = [r['dose'].l1_norm for r in sweep_results]\n",
    "        turnovers = [r['dose'].synaptic_turnover for r in sweep_results]\n",
    "        acute_persevs = [r['acute_persev'] for r in sweep_results]\n",
    "        relapse_deltas = [r['relapse_delta'] for r in sweep_results]\n",
    "\n",
    "        reductions = [untreated_metrics.perseverative_error_rate - p for p in acute_persevs]\n",
    "        efficiencies = [r / (d + 1e-8) for r, d in zip(reductions, doses)]\n",
    "\n",
    "        return {\n",
    "            'dose_range': (min(doses), max(doses)),\n",
    "            'turnover_range': (min(turnovers), max(turnovers)),\n",
    "            'best_acute_persev': min(acute_persevs),\n",
    "            'best_relapse_delta': min(relapse_deltas),\n",
    "            'max_efficiency': max(efficiencies),\n",
    "            'mean_efficiency': np.mean(efficiencies)\n",
    "        }\n",
    "\n",
    "    ket_stats = compute_sweep_stats(ketamine_results)\n",
    "    ssri_stats = compute_sweep_stats(ssri_results)\n",
    "    neuro_stats = compute_sweep_stats(neurosteroid_results)\n",
    "\n",
    "    print(\"\\n  TREATMENT SUMMARY:\")\n",
    "    print(f\"  {'Metric':<25} {'Ketamine':>15} {'SSRI':>15} {'Neurosteroid':>15}\")\n",
    "    print(\"  \" + \"-\" * 75)\n",
    "    print(f\"  {'Dose Range (L1)':<25} {ket_stats['dose_range'][0]:.4f}-{ket_stats['dose_range'][1]:.4f}\"\n",
    "          f\"   {ssri_stats['dose_range'][0]:.4f}-{ssri_stats['dose_range'][1]:.4f}\"\n",
    "          f\"   {neuro_stats['dose_range'][0]:.4f}-{neuro_stats['dose_range'][1]:.4f}\")\n",
    "    print(f\"  {'Best Acute Persev':<25} {ket_stats['best_acute_persev']:>15.4f} {ssri_stats['best_acute_persev']:>15.4f} {neuro_stats['best_acute_persev']:>15.4f}\")\n",
    "    print(f\"  {'Best Relapse Δ':<25} {ket_stats['best_relapse_delta']:>+15.4f} {ssri_stats['best_relapse_delta']:>+15.4f} {neuro_stats['best_relapse_delta']:>+15.4f}\")\n",
    "    print(f\"  {'Max Efficiency':<25} {ket_stats['max_efficiency']:>15.2f} {ssri_stats['max_efficiency']:>15.2f} {neuro_stats['max_efficiency']:>15.2f}\")\n",
    "    print(f\"  {'Mean Efficiency':<25} {ket_stats['mean_efficiency']:>15.2f} {ssri_stats['mean_efficiency']:>15.2f} {neuro_stats['mean_efficiency']:>15.2f}\")\n",
    "\n",
    "    results['summary'] = {\n",
    "        'ketamine': ket_stats,\n",
    "        'ssri': ssri_stats,\n",
    "        'neurosteroid': neuro_stats\n",
    "    }\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 7: Detailed Cognitive Results Throughout Illness Course\n",
    "    # =========================================================================\n",
    "    print_section_header(\"DETAILED COGNITIVE RESULTS THROUGHOUT ILLNESS COURSE\", char=\"═\")\n",
    "\n",
    "    # Print healthy vs OCD onset comparison\n",
    "    print_subsection_header(\"COGNITIVE DECLINE: HEALTHY BASELINE → OCD ONSET\")\n",
    "    print(\"\\n    HEALTHY BASELINE:\")\n",
    "    print_cognitive_results(healthy_cognitive, indent=6)\n",
    "    print(\"\\n    OCD ONSET (POST-PRUNING):\")\n",
    "    print_cognitive_results(ocd_onset_cognitive, indent=6)\n",
    "\n",
    "    # Compute and print cognitive decline\n",
    "    print(\"\\n    COGNITIVE DECLINE (OCD Onset - Healthy):\")\n",
    "    print(f\"      Standard Accuracy:     {ocd_onset_cognitive.standard_accuracy - healthy_cognitive.standard_accuracy:+.4f}\")\n",
    "    print(f\"      Standard Persev:       {ocd_onset_cognitive.standard_persev - healthy_cognitive.standard_persev:+.4f}\")\n",
    "    print(f\"      Rotation Accuracy:     {ocd_onset_cognitive.rotation_accuracy - healthy_cognitive.rotation_accuracy:+.4f}\")\n",
    "    print(f\"      Fine Disc Accuracy:    {ocd_onset_cognitive.fine_disc_accuracy - healthy_cognitive.fine_disc_accuracy:+.4f}\")\n",
    "    print(f\"      Blend 50% Accuracy:    {ocd_onset_cognitive.blend_50_accuracy - healthy_cognitive.blend_50_accuracy:+.4f}\")\n",
    "\n",
    "    # Print representative cognitive trajectories for each treatment\n",
    "    print_subsection_header(\"COGNITIVE TRAJECTORIES BY TREATMENT\")\n",
    "\n",
    "    # Select best configuration for each treatment for detailed trajectory\n",
    "    best_ket = min(ketamine_results, key=lambda x: x['acute_persev'])\n",
    "    best_ssri = min(ssri_results, key=lambda x: x['acute_persev'])\n",
    "    best_neuro = min(neurosteroid_results, key=lambda x: x['acute_persev'])\n",
    "\n",
    "    print(f\"\\n  KETAMINE (Best config: regrow_fraction={best_ket['param_value']:.2f})\")\n",
    "    print_cognitive_trajectory(best_ket['cognitive_trajectory'], \"ketamine\", indent=4)\n",
    "\n",
    "    print(f\"\\n  SSRI (Best config: epochs={best_ssri['param_value']})\")\n",
    "    print_cognitive_trajectory(best_ssri['cognitive_trajectory'], \"ssri\", indent=4)\n",
    "\n",
    "    print(f\"\\n  NEUROSTEROID (Best config: strength={best_neuro['param_value']:.2f})\")\n",
    "    print_cognitive_trajectory(best_neuro['cognitive_trajectory'], \"neurosteroid\", indent=4)\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 8: Cognitive Comparison at Key Stages\n",
    "    # =========================================================================\n",
    "    print_section_header(\"COGNITIVE COMPARISON AT KEY ILLNESS STAGES\", char=\"═\")\n",
    "\n",
    "    # Collect post-treatment cognitive results from best configs\n",
    "    all_post_treatment = {\n",
    "        'Healthy': [healthy_cognitive],\n",
    "        'OCD_Onset': [ocd_onset_cognitive],\n",
    "        'Ketamine_PostTx': [r for r in best_ket['cognitive_trajectory'] if r.stage == 'post_treatment'],\n",
    "        'SSRI_PostTx': [r for r in best_ssri['cognitive_trajectory'] if r.stage == 'post_treatment'],\n",
    "        'Neuro_PostTx': [r for r in best_neuro['cognitive_trajectory'] if r.stage == 'post_treatment'],\n",
    "        'Neuro_OffMed': [r for r in best_neuro['cognitive_trajectory'] if r.stage == 'off_medication'],\n",
    "    }\n",
    "\n",
    "    # Flatten if needed\n",
    "    for key in all_post_treatment:\n",
    "        if all_post_treatment[key]:\n",
    "            all_post_treatment[key] = [all_post_treatment[key][0]] if isinstance(all_post_treatment[key], list) else [all_post_treatment[key]]\n",
    "\n",
    "    # Print comprehensive comparison table\n",
    "    print_subsection_header(\"POST-TREATMENT COGNITIVE COMPARISON\")\n",
    "\n",
    "    print(\"\\n    Standard Task Performance:\")\n",
    "    print(f\"    {'Condition':<20} {'Accuracy':>12} {'Persev':>12} {'Flexibility':>12} {'Switch Cost':>12}\")\n",
    "    print(\"    \" + \"-\" * 70)\n",
    "\n",
    "    conditions = [\n",
    "        ('Healthy', healthy_cognitive),\n",
    "        ('OCD Onset', ocd_onset_cognitive),\n",
    "        ('Ketamine', best_ket['cognitive_trajectory'][-2] if len(best_ket['cognitive_trajectory']) > 1 else best_ket['cognitive_trajectory'][-1]),\n",
    "        ('SSRI', best_ssri['cognitive_trajectory'][-1]),\n",
    "        ('Neurosteroid (on)', [r for r in best_neuro['cognitive_trajectory'] if r.stage == 'post_treatment'][0] if any(r.stage == 'post_treatment' for r in best_neuro['cognitive_trajectory']) else best_neuro['cognitive_trajectory'][-2]),\n",
    "        ('Neurosteroid (off)', [r for r in best_neuro['cognitive_trajectory'] if r.stage == 'off_medication'][0] if any(r.stage == 'off_medication' for r in best_neuro['cognitive_trajectory']) else None),\n",
    "    ]\n",
    "\n",
    "    for cond_name, cog in conditions:\n",
    "        if cog is not None:\n",
    "            print(f\"    {cond_name:<20} {cog.standard_accuracy:>12.4f} {cog.standard_persev:>12.4f} \"\n",
    "                  f\"{cog.standard_flex:>12.4f} {cog.standard_switch_cost:>12.4f}\")\n",
    "\n",
    "    print(\"\\n    Cognitive Probe Performance (Accuracy):\")\n",
    "    print(f\"    {'Condition':<20} {'Rotation':>10} {'Scaling':>10} {'Fine Disc':>10} {'High Noise':>10} {'Stress':>10}\")\n",
    "    print(\"    \" + \"-\" * 72)\n",
    "\n",
    "    for cond_name, cog in conditions:\n",
    "        if cog is not None:\n",
    "            print(f\"    {cond_name:<20} {cog.rotation_accuracy:>10.4f} {cog.scaling_accuracy:>10.4f} \"\n",
    "                  f\"{cog.fine_disc_accuracy:>10.4f} {cog.high_noise_accuracy:>10.4f} {cog.high_stress_accuracy:>10.4f}\")\n",
    "\n",
    "    print(\"\\n    Sensory Integration (Blend Probes):\")\n",
    "    print(f\"    {'Condition':<20} {'Blend 25%':>12} {'Blend 50%':>12} {'Blend 75%':>12}\")\n",
    "    print(\"    \" + \"-\" * 58)\n",
    "\n",
    "    for cond_name, cog in conditions:\n",
    "        if cog is not None:\n",
    "            print(f\"    {cond_name:<20} {cog.blend_25_accuracy:>12.4f} {cog.blend_50_accuracy:>12.4f} {cog.blend_75_accuracy:>12.4f}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 9: Relapse Cognitive Impact\n",
    "    # =========================================================================\n",
    "    print_section_header(\"COGNITIVE IMPACT OF RELAPSE\", char=\"═\")\n",
    "\n",
    "    print(\"\\n    Pre-Relapse vs Post-Relapse Cognitive Comparison:\")\n",
    "    print(f\"    {'Treatment':<15} {'Measure':<20} {'Pre-Relapse':>15} {'Post-Relapse':>15} {'Change':>15}\")\n",
    "    print(\"    \" + \"-\" * 82)\n",
    "\n",
    "    for treatment_name, best_result in [('Ketamine', best_ket), ('SSRI', best_ssri), ('Neurosteroid', best_neuro)]:\n",
    "        pre = best_result['pre_relapse_cognitive']\n",
    "        post = best_result['post_relapse_cognitive']\n",
    "\n",
    "        measures = [\n",
    "            ('Std Accuracy', pre.standard_accuracy, post.standard_accuracy),\n",
    "            ('Std Persev', pre.standard_persev, post.standard_persev),\n",
    "            ('Rotation Acc', pre.rotation_accuracy, post.rotation_accuracy),\n",
    "            ('Fine Disc Acc', pre.fine_disc_accuracy, post.fine_disc_accuracy),\n",
    "            ('Blend 50%', pre.blend_50_accuracy, post.blend_50_accuracy),\n",
    "        ]\n",
    "\n",
    "        for measure_name, pre_val, post_val in measures:\n",
    "            change = post_val - pre_val\n",
    "            print(f\"    {treatment_name:<15} {measure_name:<20} {pre_val:>15.4f} {post_val:>15.4f} {change:>+15.4f}\")\n",
    "        print(\"    \" + \"-\" * 82)\n",
    "\n",
    "    # =========================================================================\n",
    "    # PHASE 10: Detailed Iso-Dose Cognitive Comparison\n",
    "    # =========================================================================\n",
    "    print_section_header(\"ISO-DOSE COGNITIVE COMPARISON\", char=\"═\")\n",
    "\n",
    "    for target_dose, comparison in results['iso_dose_comparisons'].items():\n",
    "        print(f\"\\n  TARGET DOSE: {target_dose:.6f}\")\n",
    "        print(\"  \" + \"=\" * 90)\n",
    "\n",
    "        print(f\"\\n  {'Treatment':<15} {'Parameter':<20} {'Dose L1':>10} {'ΔSparsity':>10} \"\n",
    "              f\"{'Acute Prsv':>12} {'Rotation':>10} {'Blend50':>10}\")\n",
    "        print(\"  \" + \"-\" * 90)\n",
    "\n",
    "        for treatment_name in ['ketamine', 'ssri', 'neurosteroid']:\n",
    "            match = comparison.get(treatment_name)\n",
    "            if match:\n",
    "                param_str = f\"{match['param_name']}={match['param_value']}\"\n",
    "                d = match['dose']\n",
    "\n",
    "                # Get post-treatment cognitive from trajectory\n",
    "                post_tx_cog = None\n",
    "                for cog in match['cognitive_trajectory']:\n",
    "                    if cog.stage == 'post_treatment':\n",
    "                        post_tx_cog = cog\n",
    "                        break\n",
    "\n",
    "                if post_tx_cog:\n",
    "                    print(f\"  {treatment_name.capitalize():<15} {param_str:<20} {d.l1_norm:>10.6f} \"\n",
    "                          f\"{d.sparsity_change:>10.4f} {match['acute_persev']:>12.4f} \"\n",
    "                          f\"{post_tx_cog.rotation_accuracy:>10.4f} {post_tx_cog.blend_50_accuracy:>10.4f}\")\n",
    "                else:\n",
    "                    print(f\"  {treatment_name.capitalize():<15} {param_str:<20} {d.l1_norm:>10.6f} \"\n",
    "                          f\"{d.sparsity_change:>10.4f} {match['acute_persev']:>12.4f} \"\n",
    "                          f\"{'N/A':>10} {'N/A':>10}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # =========================================================================\n",
    "    print_section_header(\"EXPERIMENT SUMMARY\", char=\"█\")\n",
    "\n",
    "    print(\"\"\"\n",
    "  COGNITIVE TESTING THROUGHOUT ILLNESS COURSE:\n",
    "\n",
    "  1. BASELINE ASSESSMENTS:\n",
    "     - Healthy (fully trained, pre-pruning)\n",
    "     - OCD Onset (immediately post-pruning)\n",
    "\n",
    "  2. TREATMENT PHASES ASSESSED:\n",
    "     - Pre-treatment (untreated OCD state)\n",
    "     - During treatment (SSRI: multiple timepoints)\n",
    "     - Immediate medication effect (Neurosteroid)\n",
    "     - Post-treatment (all treatments)\n",
    "     - Off-medication (Neurosteroid)\n",
    "\n",
    "  3. RELAPSE SIMULATION:\n",
    "     - Pre-relapse cognitive state\n",
    "     - Post-relapse cognitive state\n",
    "     - Cognitive decline quantified\n",
    "\n",
    "  4. COGNITIVE DOMAINS TESTED:\n",
    "     - Standard task (rule-switching accuracy, perseveration, flexibility)\n",
    "     - Rotation probe (cognitive flexibility/generalization)\n",
    "     - Scaling probe (visuospatial processing)\n",
    "     - Fine discrimination (attention/perceptual acuity)\n",
    "     - High noise (distraction resistance)\n",
    "     - High stress (stress resilience)\n",
    "     - Sensory integration (conflicting stream blending at 25/50/75%)\n",
    "\n",
    "  5. ISO-DOSE COMPARISON:\n",
    "     - Fair comparison at matched network change levels\n",
    "     - Cognitive outcomes compared at equivalent \"doses\"\n",
    "    \"\"\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ORIGINAL MULTI-MECHANISM COMPARISON (ENHANCED WITH COGNITIVE TRACKING)\n",
    "# =============================================================================\n",
    "\n",
    "def run_multi_mechanism_ocd_experiment(\n",
    "    device: torch.device,\n",
    "    seed: int = None,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Compare three antidepressant mechanisms in OCD pruning framework with cognitive tracking.\"\"\"\n",
    "    if seed is None:\n",
    "        seed = CONFIG['seed']\n",
    "    set_seed(seed)\n",
    "\n",
    "    print_section_header(\"MULTI-MECHANISM ANTIDEPRESSANT COMPARISON\", char=\"█\")\n",
    "    print_section_header(\"WITH COGNITIVE TESTING THROUGHOUT ILLNESS\", char=\"█\")\n",
    "    print(f\"\\n  Comparing treatment mechanisms in OCD model (Seed: {seed})\")\n",
    "\n",
    "    train_loader, test_loader, _ = create_rule_switch_dataloaders()\n",
    "    probe_loaders = create_cognitive_probe_loaders()\n",
    "\n",
    "    print_subsection_header(\"PHASE 1: Creating Shared Pruned Baseline\")\n",
    "\n",
    "    base_model = CSTCNetwork().to(device)\n",
    "    print(\"  Training healthy baseline model...\")\n",
    "    train(base_model, train_loader, test_loader, verbose=False)\n",
    "\n",
    "    # Healthy baseline cognitive assessment\n",
    "    healthy_cognitive = run_comprehensive_cognitive_evaluation(\n",
    "        base_model, probe_loaders, device,\n",
    "        stage=\"healthy_baseline\",\n",
    "        treatment=\"none\",\n",
    "        timepoint_detail=\"fully_trained\"\n",
    "    )\n",
    "\n",
    "    base_mgr = CSTCPruningManager(base_model)\n",
    "    prune_stats = base_mgr.prune_by_magnitude(sparsity=CONFIG['ocd_prune_sparsity'])\n",
    "\n",
    "    print(f\"  Applied developmental over-pruning: {CONFIG['ocd_prune_sparsity']*100:.0f}%\")\n",
    "    print(f\"  Achieved sparsity: {prune_stats['achieved_sparsity']*100:.1f}%\")\n",
    "\n",
    "    # OCD onset cognitive assessment\n",
    "    ocd_onset_cognitive = run_comprehensive_cognitive_evaluation(\n",
    "        base_model, probe_loaders, device,\n",
    "        stage=\"ocd_onset\",\n",
    "        treatment=\"untreated\",\n",
    "        timepoint_detail=\"post_pruning\"\n",
    "    )\n",
    "\n",
    "    base_state = copy.deepcopy(base_model.state_dict())\n",
    "    base_masks = copy.deepcopy(base_mgr.masks)\n",
    "\n",
    "    results = {\n",
    "        'cognitive_baselines': {\n",
    "            'healthy': healthy_cognitive,\n",
    "            'ocd_onset': ocd_onset_cognitive\n",
    "        },\n",
    "        'treatment_trajectories': {}\n",
    "    }\n",
    "\n",
    "    print_subsection_header(\"PHASE 2: Untreated Baseline Evaluation\")\n",
    "\n",
    "    untreated_metrics = compute_ocd_metrics(base_model, test_loader, device)\n",
    "    results['untreated'] = {\n",
    "        'sparsity': untreated_metrics.sparsity,\n",
    "        'accuracy': untreated_metrics.accuracy,\n",
    "        'persev': untreated_metrics.perseverative_error_rate,\n",
    "        'switch_cost': untreated_metrics.switch_cost,\n",
    "        'flex_index': untreated_metrics.flexibility_index,\n",
    "        'repetition_rate': untreated_metrics.repetition_rate,\n",
    "        'trials_to_recover': untreated_metrics.trials_to_recover\n",
    "    }\n",
    "\n",
    "    print(f\"  UNTREATED OCD STATE:\")\n",
    "    print(f\"    Sparsity:              {untreated_metrics.sparsity*100:.1f}%\")\n",
    "    print(f\"    Accuracy:              {untreated_metrics.accuracy:.4f}\")\n",
    "    print(f\"    Perseverative Errors:  {untreated_metrics.perseverative_error_rate:.4f}\")\n",
    "    print(f\"    Flexibility Index:     {untreated_metrics.flexibility_index:.4f}\")\n",
    "\n",
    "    def clone_baseline():\n",
    "        model = CSTCNetwork().to(device)\n",
    "        model.load_state_dict(copy.deepcopy(base_state))\n",
    "        mgr = CSTCPruningManager(model)\n",
    "        mgr.masks = copy.deepcopy(base_masks)\n",
    "        mgr.apply_masks()\n",
    "        return model, mgr\n",
    "\n",
    "    treatments = ['ketamine', 'ssri', 'neurosteroid']\n",
    "\n",
    "    for treatment in treatments:\n",
    "        print_subsection_header(f\"PHASE 3: {treatment.upper()} Treatment\")\n",
    "\n",
    "        model, mgr = clone_baseline()\n",
    "\n",
    "        pre_state = {n: p.data.clone() for n, p in model.named_parameters() if 'weight' in n}\n",
    "\n",
    "        if treatment == 'ketamine':\n",
    "            treatment_info, cog_trajectory = ketamine_treatment_ocd(\n",
    "                model, mgr, train_loader, test_loader, probe_loaders, device,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        elif treatment == 'ssri':\n",
    "            treatment_info, cog_trajectory = ssri_treatment_ocd(\n",
    "                model, mgr, train_loader, test_loader, probe_loaders, device,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        elif treatment == 'neurosteroid':\n",
    "            treatment_info, cog_trajectory = neurosteroid_treatment_ocd(\n",
    "                model, mgr, train_loader, test_loader, probe_loaders, device,\n",
    "                verbose=verbose\n",
    "            )\n",
    "\n",
    "        results['treatment_trajectories'][treatment] = cog_trajectory\n",
    "\n",
    "        dose_metrics = compute_all_dose_metrics(pre_state, model)\n",
    "\n",
    "        acute_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "        off_med_metrics = None\n",
    "        if treatment == 'neurosteroid':\n",
    "            model.set_inhibition(1.0, False)\n",
    "            off_med_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "            model.set_inhibition(\n",
    "                CONFIG['comparison_neurosteroid_strength'],\n",
    "                CONFIG['comparison_neurosteroid_use_tanh']\n",
    "            )\n",
    "\n",
    "        # Pre-relapse cognitive assessment\n",
    "        pre_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "            model, probe_loaders, device,\n",
    "            stage=\"pre_relapse\",\n",
    "            treatment=treatment,\n",
    "            timepoint_detail=\"before_secondary_pruning\"\n",
    "        )\n",
    "\n",
    "        pre_relapse_persev = acute_metrics.perseverative_error_rate\n",
    "        pre_relapse_flex = acute_metrics.flexibility_index\n",
    "        pre_relapse_acc = acute_metrics.accuracy\n",
    "\n",
    "        mgr.secondary_prune(fraction=CONFIG['relapse_prune_fraction'])\n",
    "\n",
    "        # Post-relapse cognitive assessment\n",
    "        post_relapse_cog = run_comprehensive_cognitive_evaluation(\n",
    "            model, probe_loaders, device,\n",
    "            stage=\"post_relapse\",\n",
    "            treatment=treatment,\n",
    "            timepoint_detail=\"after_secondary_pruning\"\n",
    "        )\n",
    "\n",
    "        relapse_metrics = compute_ocd_metrics(model, test_loader, device)\n",
    "\n",
    "        relapse_delta_persev = relapse_metrics.perseverative_error_rate - pre_relapse_persev\n",
    "        relapse_delta_flex = pre_relapse_flex - relapse_metrics.flexibility_index\n",
    "        relapse_delta_acc = pre_relapse_acc - relapse_metrics.accuracy\n",
    "\n",
    "        results[treatment] = {\n",
    "            'treatment_info': treatment_info,\n",
    "            'dose_metrics': {\n",
    "                'l1_norm': dose_metrics.l1_norm,\n",
    "                'l2_norm': dose_metrics.l2_norm,\n",
    "                'synaptic_turnover': dose_metrics.synaptic_turnover,\n",
    "                'sparsity_change': dose_metrics.sparsity_change\n",
    "            },\n",
    "            'acute_sparsity': acute_metrics.sparsity,\n",
    "            'acute_accuracy': acute_metrics.accuracy,\n",
    "            'acute_persev': acute_metrics.perseverative_error_rate,\n",
    "            'acute_flex': acute_metrics.flexibility_index,\n",
    "            'acute_repetition': acute_metrics.repetition_rate,\n",
    "            'acute_switch_cost': acute_metrics.switch_cost,\n",
    "            'acute_recovery': acute_metrics.trials_to_recover,\n",
    "            'improvement_persev': untreated_metrics.perseverative_error_rate - acute_metrics.perseverative_error_rate,\n",
    "            'improvement_flex': acute_metrics.flexibility_index - untreated_metrics.flexibility_index,\n",
    "            'improvement_acc': acute_metrics.accuracy - untreated_metrics.accuracy,\n",
    "            'relapse_sparsity': relapse_metrics.sparsity,\n",
    "            'relapse_persev': relapse_metrics.perseverative_error_rate,\n",
    "            'relapse_flex': relapse_metrics.flexibility_index,\n",
    "            'relapse_delta_persev': relapse_delta_persev,\n",
    "            'relapse_delta_flex': relapse_delta_flex,\n",
    "            'relapse_delta_acc': relapse_delta_acc,\n",
    "            'off_med_persev': off_med_metrics.perseverative_error_rate if off_med_metrics else None,\n",
    "            'off_med_flex': off_med_metrics.flexibility_index if off_med_metrics else None,\n",
    "            'off_med_acc': off_med_metrics.accuracy if off_med_metrics else None,\n",
    "            'cognitive_trajectory': cog_trajectory,\n",
    "            'pre_relapse_cognitive': pre_relapse_cog,\n",
    "            'post_relapse_cognitive': post_relapse_cog,\n",
    "        }\n",
    "\n",
    "        print(f\"\\n    DOSE METRICS:\")\n",
    "        print(f\"      L1 Weight Change:    {dose_metrics.l1_norm:.6f}\")\n",
    "        print(f\"      L2 Weight Change:    {dose_metrics.l2_norm:.6f}\")\n",
    "        print(f\"      Synaptic Turnover:   {dose_metrics.synaptic_turnover:.4f}\")\n",
    "        print(f\"      Sparsity Change:     {dose_metrics.sparsity_change:.4f}\")\n",
    "\n",
    "        print(f\"\\n    ACUTE EFFECTS:\")\n",
    "        print(f\"      Sparsity:            {acute_metrics.sparsity*100:.1f}%\")\n",
    "        print(f\"      Accuracy:            {acute_metrics.accuracy:.4f} (Δ = {results[treatment]['improvement_acc']:+.4f})\")\n",
    "        print(f\"      Perseveration:       {acute_metrics.perseverative_error_rate:.4f} (Δ = {-results[treatment]['improvement_persev']:+.4f})\")\n",
    "        print(f\"      Flexibility:         {acute_metrics.flexibility_index:.4f} (Δ = {results[treatment]['improvement_flex']:+.4f})\")\n",
    "\n",
    "        efficiency = results[treatment]['improvement_persev'] / (dose_metrics.l1_norm + 1e-8)\n",
    "        print(f\"      Efficiency:          {efficiency:.2f} (persev reduction / dose)\")\n",
    "\n",
    "        if off_med_metrics:\n",
    "            print(f\"\\n    OFF-MEDICATION TEST:\")\n",
    "            print(f\"      Perseveration:       {off_med_metrics.perseverative_error_rate:.4f}\")\n",
    "            off_med_delta = off_med_metrics.perseverative_error_rate - acute_metrics.perseverative_error_rate\n",
    "            print(f\"      Reversal:            {off_med_delta:+.4f} perseveration increase\")\n",
    "\n",
    "        print(f\"\\n    RELAPSE SIMULATION ({CONFIG['relapse_prune_fraction']*100:.0f}% secondary pruning):\")\n",
    "        print(f\"      Sparsity:            {relapse_metrics.sparsity*100:.1f}%\")\n",
    "        print(f\"      Perseveration:       {relapse_metrics.perseverative_error_rate:.4f} (Δ = {relapse_delta_persev:+.4f})\")\n",
    "        print(f\"      Flexibility:         {relapse_metrics.flexibility_index:.4f} (Δ = {-relapse_delta_flex:+.4f})\")\n",
    "\n",
    "        # Print cognitive trajectory summary\n",
    "        print(f\"\\n    COGNITIVE TRAJECTORY SUMMARY:\")\n",
    "        for cog in cog_trajectory:\n",
    "            print(f\"      [{cog.stage}] {cog.timepoint_detail}: Acc={cog.standard_accuracy:.4f}, \"\n",
    "                  f\"Persev={cog.standard_persev:.4f}, Rot={cog.rotation_accuracy:.4f}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # COMPREHENSIVE COMPARISON TABLES\n",
    "    # =========================================================================\n",
    "    print_section_header(\"COMPREHENSIVE TREATMENT COMPARISON\", char=\"═\")\n",
    "\n",
    "    print(\"\\n  DOSE COMPARISON:\")\n",
    "    print(f\"  {'Treatment':<15} {'L1 Dose':>12} {'L2 Dose':>12} {'Turnover':>12} {'ΔSparsity':>12}\")\n",
    "    print(\"  \" + \"-\" * 65)\n",
    "    for treatment in treatments:\n",
    "        dm = results[treatment]['dose_metrics']\n",
    "        print(f\"  {treatment.capitalize():<15} {dm['l1_norm']:>12.6f} {dm['l2_norm']:>12.6f} \"\n",
    "              f\"{dm['synaptic_turnover']:>12.4f} {dm['sparsity_change']:>12.4f}\")\n",
    "\n",
    "    print(\"\\n  ACUTE EFFECTS:\")\n",
    "    print(f\"  {'Treatment':<15} {'Sparsity':>10} {'Accuracy':>10} {'Persev':>10} {'Flex':>10} {'Efficiency':>12}\")\n",
    "    print(\"  \" + \"-\" * 70)\n",
    "    print(f\"  {'Untreated':<15} {results['untreated']['sparsity']*100:>9.1f}% \"\n",
    "          f\"{results['untreated']['accuracy']:>10.4f} {results['untreated']['persev']:>10.4f} \"\n",
    "          f\"{results['untreated']['flex_index']:>10.4f} {'N/A':>12}\")\n",
    "\n",
    "    for treatment in treatments:\n",
    "        r = results[treatment]\n",
    "        efficiency = r['improvement_persev'] / (r['dose_metrics']['l1_norm'] + 1e-8)\n",
    "        print(f\"  {treatment.capitalize():<15} {r['acute_sparsity']*100:>9.1f}% \"\n",
    "              f\"{r['acute_accuracy']:>10.4f} {r['acute_persev']:>10.4f} \"\n",
    "              f\"{r['acute_flex']:>10.4f} {efficiency:>12.2f}\")\n",
    "\n",
    "    print(\"\\n  RELAPSE VULNERABILITY:\")\n",
    "    print(f\"  {'Treatment':<15} {'ΔPersev':>12} {'ΔFlexibility':>12} {'Interpretation':<25}\")\n",
    "    print(\"  \" + \"-\" * 70)\n",
    "\n",
    "    for treatment in treatments:\n",
    "        r = results[treatment]\n",
    "        if r['relapse_delta_persev'] < 0.02:\n",
    "            interp = \"Relapse resistant\"\n",
    "        elif r['relapse_delta_persev'] < 0.05:\n",
    "            interp = \"Moderate relapse\"\n",
    "        else:\n",
    "            interp = \"High relapse risk\"\n",
    "\n",
    "        print(f\"  {treatment.capitalize():<15} {r['relapse_delta_persev']:>+12.4f} \"\n",
    "              f\"{-r['relapse_delta_flex']:>+12.4f} {interp:<25}\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # COGNITIVE COMPARISON ACROSS TREATMENTS\n",
    "    # =========================================================================\n",
    "    print_section_header(\"COGNITIVE COMPARISON ACROSS TREATMENTS\", char=\"═\")\n",
    "\n",
    "    # Post-treatment comparison\n",
    "    print_subsection_header(\"POST-TREATMENT COGNITIVE STATE\")\n",
    "\n",
    "    print(\"\\n  Standard Task Performance:\")\n",
    "    print(f\"  {'Condition':<20} {'Accuracy':>12} {'Persev':>12} {'Flexibility':>12}\")\n",
    "    print(\"  \" + \"-\" * 58)\n",
    "    print(f\"  {'Healthy Baseline':<20} {healthy_cognitive.standard_accuracy:>12.4f} \"\n",
    "          f\"{healthy_cognitive.standard_persev:>12.4f} {healthy_cognitive.standard_flex:>12.4f}\")\n",
    "    print(f\"  {'OCD Onset':<20} {ocd_onset_cognitive.standard_accuracy:>12.4f} \"\n",
    "          f\"{ocd_onset_cognitive.standard_persev:>12.4f} {ocd_onset_cognitive.standard_flex:>12.4f}\")\n",
    "\n",
    "    for treatment in treatments:\n",
    "        post_tx = [c for c in results['treatment_trajectories'][treatment] if c.stage == 'post_treatment']\n",
    "        if post_tx:\n",
    "            c = post_tx[0]\n",
    "            print(f\"  {treatment.capitalize() + ' (Post-Tx)':<20} {c.standard_accuracy:>12.4f} \"\n",
    "                  f\"{c.standard_persev:>12.4f} {c.standard_flex:>12.4f}\")\n",
    "\n",
    "    # Cognitive probes comparison\n",
    "    print(\"\\n  Cognitive Probe Performance (Accuracy):\")\n",
    "    print(f\"  {'Condition':<20} {'Rotation':>10} {'Scaling':>10} {'Fine Disc':>10} {'High Noise':>10}\")\n",
    "    print(\"  \" + \"-\" * 62)\n",
    "    print(f\"  {'Healthy Baseline':<20} {healthy_cognitive.rotation_accuracy:>10.4f} \"\n",
    "          f\"{healthy_cognitive.scaling_accuracy:>10.4f} {healthy_cognitive.fine_disc_accuracy:>10.4f} \"\n",
    "          f\"{healthy_cognitive.high_noise_accuracy:>10.4f}\")\n",
    "    print(f\"  {'OCD Onset':<20} {ocd_onset_cognitive.rotation_accuracy:>10.4f} \"\n",
    "          f\"{ocd_onset_cognitive.scaling_accuracy:>10.4f} {ocd_onset_cognitive.fine_disc_accuracy:>10.4f} \"\n",
    "          f\"{ocd_onset_cognitive.high_noise_accuracy:>10.4f}\")\n",
    "\n",
    "    for treatment in treatments:\n",
    "        post_tx = [c for c in results['treatment_trajectories'][treatment] if c.stage == 'post_treatment']\n",
    "        if post_tx:\n",
    "            c = post_tx[0]\n",
    "            print(f\"  {treatment.capitalize() + ' (Post-Tx)':<20} {c.rotation_accuracy:>10.4f} \"\n",
    "                  f\"{c.scaling_accuracy:>10.4f} {c.fine_disc_accuracy:>10.4f} \"\n",
    "                  f\"{c.high_noise_accuracy:>10.4f}\")\n",
    "\n",
    "    # Sensory integration\n",
    "    print(\"\\n  Sensory Integration (Blend Probes):\")\n",
    "    print(f\"  {'Condition':<20} {'Blend 25%':>12} {'Blend 50%':>12} {'Blend 75%':>12}\")\n",
    "    print(\"  \" + \"-\" * 58)\n",
    "    print(f\"  {'Healthy Baseline':<20} {healthy_cognitive.blend_25_accuracy:>12.4f} \"\n",
    "          f\"{healthy_cognitive.blend_50_accuracy:>12.4f} {healthy_cognitive.blend_75_accuracy:>12.4f}\")\n",
    "    print(f\"  {'OCD Onset':<20} {ocd_onset_cognitive.blend_25_accuracy:>12.4f} \"\n",
    "          f\"{ocd_onset_cognitive.blend_50_accuracy:>12.4f} {ocd_onset_cognitive.blend_75_accuracy:>12.4f}\")\n",
    "\n",
    "    for treatment in treatments:\n",
    "        post_tx = [c for c in results['treatment_trajectories'][treatment] if c.stage == 'post_treatment']\n",
    "        if post_tx:\n",
    "            c = post_tx[0]\n",
    "            print(f\"  {treatment.capitalize() + ' (Post-Tx)':<20} {c.blend_25_accuracy:>12.4f} \"\n",
    "                  f\"{c.blend_50_accuracy:>12.4f} {c.blend_75_accuracy:>12.4f}\")\n",
    "\n",
    "    # Relapse cognitive impact\n",
    "    print_subsection_header(\"COGNITIVE IMPACT OF RELAPSE\")\n",
    "\n",
    "    print(\"\\n  Change in Cognitive Performance After Relapse:\")\n",
    "    print(f\"  {'Treatment':<15} {'ΔStd Acc':>12} {'ΔRotation':>12} {'ΔFine Disc':>12} {'ΔBlend 50%':>12}\")\n",
    "    print(\"  \" + \"-\" * 65)\n",
    "\n",
    "    for treatment in treatments:\n",
    "        pre = results[treatment]['pre_relapse_cognitive']\n",
    "        post = results[treatment]['post_relapse_cognitive']\n",
    "        print(f\"  {treatment.capitalize():<15} {post.standard_accuracy - pre.standard_accuracy:>+12.4f} \"\n",
    "              f\"{post.rotation_accuracy - pre.rotation_accuracy:>+12.4f} \"\n",
    "              f\"{post.fine_disc_accuracy - pre.fine_disc_accuracy:>+12.4f} \"\n",
    "              f\"{post.blend_50_accuracy - pre.blend_50_accuracy:>+12.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN ENTRY POINT\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run full OCD hypothesis validation suite with cognitive testing throughout illness course.\"\"\"\n",
    "    print(\"\\n\" + \"█\" * 80)\n",
    "    print(\"█\" + \" \" * 78 + \"█\")\n",
    "    print(\"█\" + \"COMPUTATIONAL MODEL: OCD SYNAPTIC PRUNING HYPOTHESIS\".center(78) + \"█\")\n",
    "    print(\"█\" + \"WITH COGNITIVE TESTING THROUGHOUT ILLNESS COURSE\".center(78) + \"█\")\n",
    "    print(\"█\" + \"AND ISO-DOSE FAIR COMPARISON PIPELINE\".center(78) + \"█\")\n",
    "    print(\"█\" + \" \" * 78 + \"█\")\n",
    "    print(\"█\" * 80)\n",
    "\n",
    "    print(f\"\\n  PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"  Device: {DEVICE}\")\n",
    "    print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    set_seed(CONFIG['seed'])\n",
    "\n",
    "    print(\"\\n  Running Multi-Mechanism Comparison (with cognitive tracking)...\")\n",
    "    multi_results = run_multi_mechanism_ocd_experiment(DEVICE, verbose=True)\n",
    "\n",
    "    print(\"\\n  Running Iso-Dose Comparison Experiment (with cognitive tracking)...\")\n",
    "    iso_dose_results = run_iso_dose_comparison_experiment(DEVICE, verbose=True)\n",
    "\n",
    "    print(\"\\n\" + \"█\" * 80)\n",
    "    print(\"█\" + \"EXPERIMENT COMPLETE\".center(78) + \"█\")\n",
    "    print(\"█\" * 80)\n",
    "\n",
    "    return {\n",
    "        'multi_mechanism': multi_results,\n",
    "        'iso_dose': iso_dose_results\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The end"
   ],
   "metadata": {
    "id": "MmHpavLyi-cS"
   }
  }
 ]
}
